{"version":3,"file":"umd.js","sources":["../src/internals.ts","../src/eval.ts","../src/io.ts"],"sourcesContent":["/*!\n * Copyright (c) 2017-2018 by The Funfix Project Developers.\n * Some rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * We don't need the full power of JS's iterators, just a way\n * to traverse data structures.\n *\n * @hidden\n */\nexport interface IteratorLike<A> {\n  next(): { done: boolean, value?: A }\n}\n\n/**\n * Reusable empty `IteratorLike` reference.\n *\n * @hidden\n */\nexport const emptyIteratorRef: IteratorLike<never> =\n  { next: () => ({ done: true }) }\n\n/**\n * Given an array or an `Iterable`, returns a simple iterator type\n * that we can use to traverse the given list lazily.\n *\n * @hidden\n */\nexport function iteratorOf<A>(list: A[] | Iterable<A>): IteratorLike<A> {\n  if (!list) return emptyIteratorRef\n  if (Object.prototype.toString.call(list) !== \"[object Array]\")\n    return list[Symbol.iterator]()\n\n  const array = list as A[]\n  if (array.length === 0) return emptyIteratorRef\n\n  let cursor = 0\n  const next = () => {\n    const value = array[cursor++]\n    const done = cursor >= array.length\n    return { done, value }\n  }\n\n  return { next }\n}\n","/*!\n * Copyright (c) 2017-2018 by The Funfix Project Developers.\n * Some rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { HK, Monad } from \"funland\"\nimport { Either, Throwable, coreInternals } from \"funfix-core\"\nimport {\n  IteratorLike,\n  iteratorOf\n} from \"./internals\"\n\n/**\n * Eval is a monad which controls evaluation.\n *\n * This type wraps a value (or an expression that produces a value)\n * and can produce it on command via the {@link Eval.get get()}\n * method.\n *\n * There are three basic evaluation strategies:\n *\n *  - {@link Eval.now}: for describing strict values, evaluated\n *    immediately\n *  - {@link Eval.once}: evaluated only once when the value is needed,\n *    with the result memoized (cached) for subsequent evaluations\n *  - [[Eval.always]]: evaluated every time the value is needed,\n *    being equivalent to a function\n *\n * Eval supports stack-safe lazy computation via the {@link Eval.map .map}\n * and {@link Eval.flatMap .flatMap} methods, which use an internal\n * trampoline to avoid stack overflows. Computation done within `map`\n * and `flatMap` is always done lazily, even when applied to an\n * `Eval.now` instance.\n *\n * Use `map` and `flatMap` to chain computation, and use `get()` to\n * get the result when needed. It is also not good style to create\n * `Eval` instances whose computation involves calling `get()` on\n * another `Eval` instance -- this can defeat the trampolining and\n * lead to stack overflows.\n *\n * ```typescript\n * const rndInt = Eval.of(() => {\n *   const nr = Math.random() * 1000000\n *   return nr & nr\n * })\n *\n * const evenInt = () =>\n *   rndInt.flatMap(int => {\n *     if (i % 2 == 0)\n *       return Eval.now(i)\n *     else // Retry until we have an even number!\n *       return evenInt()\n *   })\n *\n * const cached = evenInt().memoize()\n *\n * // Nothing happens until now, this triggers the\n * // actual evaluation:\n * const n: number = cached.get()\n * ```\n *\n * ## Versus IO\n *\n * For dealing with lazy evaluation, the other alternative is\n * the {@link IO} data type.\n *\n * Differences between `Eval` and `IO`:\n *\n * 1. `IO` is capable of describing asynchronous computations as well\n * 2. `IO` is capable of error handling (it implements `MonadError`),\n *    whereas `Eval` does not provide error handling capabilities,\n *    being meant to be used for pure expressions (it implements\n *    `Comonad`, which is incompatible with `MonadError`)\n *\n * So if you need error handling capabilities\n * (i.e. `MonadError<Throwable, ?>`), or if you need to describe\n * asynchronous processes, then {@link IO} is for you. `Eval`\n * is a simpler data type with the sole purpose of controlling the\n * evaluation of expressions (i.e. strict versus lazy).\n *\n * ## Credits\n *\n * This type is inspired by `cats.Eval` from\n * {@link http://typelevel.org/cats/|Typelevel Cats}\n * and by `monix.eval.Coeval` from {@link https://monix.io|Monix}.\n *\n * @final\n */\nexport class Eval<A> implements HK<\"funfix/eval\", A> {\n  /**\n   * Evaluates the source `Eval` and returns the result.\n   *\n   * ```typescript\n   * const ref = Eval.always(() => 100 * 2)\n   *\n   * ref.get() // 200\n   * ```\n   */\n  get(): A { return evalRunLoop(this) }\n\n  /**\n   * Returns a new `Eval` that applies the mapping function to the\n   * successful result emitted by the source.\n   *\n   * ```typescript\n   * Eval.now(111).map(_ => _ * 2).get() // 222\n   * ```\n   */\n  map<B>(f: (a: A) => B): Eval<B> {\n    return new FlatMap(this, (a: A) => Eval.now(f(a)))\n  }\n\n  /**\n   * Creates a new `Eval` by applying a function to the successful\n   * result of the source, and returns a new instance equivalent to\n   * the result of the function.\n   *\n   * ```typescript\n   * const rndInt = Eval.of(() => {\n   *   const nr = Math.random() * 1000000\n   *   return nr & nr\n   * })\n   *\n   * const evenInt = () =>\n   *   rndInt.flatMap(int => {\n   *     if (i % 2 == 0)\n   *       return Eval.now(i)\n   *     else // Retry until we have an even number!\n   *       return evenInt()\n   *   })\n   * ```\n   */\n  flatMap<B>(f: (a: A) => Eval<B>): Eval<B> {\n    return new FlatMap(this, f)\n  }\n\n  /** Alias for {@link flatMap}. */\n  chain<B>(f: (a: A) => Eval<B>): Eval<B> {\n    return this.flatMap(f)\n  }\n\n  /**\n   * `Applicative` apply operator.\n   *\n   * Resembles {@link map}, but the passed mapping function is\n   * lifted in the `Either` context.\n   */\n  ap<B>(ff: Eval<(a: A) => B>): Eval<B> {\n    return ff.flatMap(f => this.map(f))\n  }\n\n  /**\n   * Memoizes (caches) the result of the source on the first\n   * evaluation and reuses it on subsequent invocations of `get()`.\n   *\n   * The resulting `Eval` will be idempotent, meaning that\n   * evaluating it multiple times will have the same effect\n   * as evaluating it once.\n   */\n  memoize(): Eval<A> {\n    switch (this._tag) {\n      case \"now\":\n      case \"once\":\n        return this\n      case \"always\":\n        return new Once(this.get)\n      default:\n        return new Once(() => this.get())\n    }\n  }\n\n  /**\n   * Returns a new `Eval` that upon evaluation will execute the given\n   * function for the generated element, transforming the source into\n   * an `Eval<void>`.\n   *\n   * Similar in spirit with normal {@link Eval.forEach .forEach},\n   * but lazy, as obviously nothing gets executed at this point.\n   */\n  forEachL(cb: (a: A) => void): Eval<void> {\n    return this.map(cb)\n  }\n\n  /**\n   * Triggers the evaluation of the source, executing the given\n   * function for the generated element.\n   *\n   * The application of this function has strict behavior, as the\n   * coeval is immediately executed.\n   */\n  forEach(cb: (a: A) => void): void {\n    this.forEachL(cb).get()\n  }\n\n  /**\n   * Identifies the `Eval` reference type, useful for debugging and\n   * for pattern matching in the implementation.\n   *\n   * @hidden\n   */\n  readonly _tag!: \"now\" | \"always\" | \"once\" | \"suspend\" | \"flatMap\"\n\n  // Implements HK<F, A>\n  /** @hidden */ readonly _URI!: \"funfix/eval\"\n  /** @hidden */ readonly _A!: A\n  // Implements Constructor<T>\n  /** @hidden */ static readonly _Class: Eval<any>\n\n  /**\n   * Alias for {@link Eval.always}.\n   */\n  static of<A>(thunk: () => A): Eval<A> {\n    return Eval.always(thunk)\n  }\n\n  /**\n   * Lifts a value into the `Eval` context.\n   *\n   * Alias for {@link Eval.now}.\n   */\n  static pure<A>(value: A): Eval<A> { return Eval.now(value) }\n\n  /**\n   * Returns an `Eval` that on execution is always successful,\n   * emitting the given strict value.\n   */\n  static now<A>(value: A): Eval<A> { return new Now(value) }\n\n  /**\n   * Shorthand for `now(undefined as void)`, always returning\n   * the same reference as optimization.\n   */\n  static unit(): Eval<void> {\n    return evalUnitRef\n  }\n\n  /**\n   * Promote a `thunk` function to an `Eval`, catching exceptions in\n   * the process.\n   *\n   * Note that since `Eval` is not memoized by global, this will\n   * recompute the value each time the `Eval` is executed.\n   */\n  static always<A>(thunk: () => A): Eval<A> {\n    return new Always(thunk)\n  }\n\n  /**\n   * Promote a `thunk` function to a `Coeval` that is memoized on the\n   * first evaluation, the result being then available on subsequent\n   * evaluations.\n   *\n   * Note this is equivalent with:\n   *\n   * ```typescript\n   * Eval.always(thunk).memoize()\n   * ```\n   */\n  static once<A>(thunk: () => A): Eval<A> {\n    return new Once(thunk)\n  }\n\n  /**\n   * Promote a `thunk` function generating `Eval` results to an `Eval`\n   * of the same type.\n   */\n  static suspend<A>(thunk: () => Eval<A>): Eval<A> {\n    return new Suspend(thunk)\n  }\n\n  /**\n   * Promote a `thunk` function generating `Eval` results to an `Eval`\n   * of the same type.\n   *\n   * Alias for {@link Eval.suspend}.\n   */\n  static defer<A>(thunk: () => Eval<A>): Eval<A> {\n    return Eval.suspend(thunk)\n  }\n\n  /**\n   * Keeps calling `f` until a `Right(b)` is returned.\n   *\n   * Based on Phil Freeman's\n   * [Stack Safety for Free]{@link http://functorial.com/stack-safety-for-free/index.pdf}.\n   *\n   * Described in `FlatMap.tailRecM`.\n   */\n  static tailRecM<A, B>(a: A, f: (a: A) => Eval<Either<A, B>>): Eval<B> {\n    return f(a).flatMap(either => {\n      if (either.isRight()) {\n        return Eval.now(either.get())\n      } else {\n        // Recursive call\n        return Eval.tailRecM(either.swap().get(), f)\n      }\n    })\n  }\n\n  /**\n   * Transforms a list of `Eval` values into an `Eval` of a list.\n   *\n   * Sample:\n   *\n   * ```typescript\n   * const io1 = Eval.of(() => 1)\n   * const io2 = Eval.of(() => 2)\n   * const io3 = Eval.of(() => 3)\n   *\n   * // Yields [1, 2, 3]\n   * const all: Eval<number[]> = Eval.sequence([f1, f2, f3])\n   * ```\n   */\n  static sequence<A>(list: Eval<A>[] | Iterable<Eval<A>>): Eval<A[]> {\n    return evalSequence(list)\n  }\n\n  /**\n   * Maps 2 `Eval` values by the mapping function, returning a new\n   * `Eval` reference that completes with the result of mapping that\n   * function to the successful values of the futures, or in failure in\n   * case either of them fails.\n   *\n   * ```typescript\n   * const fa1 = Eval.of(() => 1)\n   * const fa2 = Eval.of(() => 2)\n   *\n   *\n   * // Yields Success(3)\n   * Eval.map2(fa1, fa2, (a, b) => a + b)\n   * ```\n   *\n   * This operation is the `Applicative.map2`.\n   */\n  static map2<A1, A2, R>(\n    fa1: Eval<A1>, fa2: Eval<A2>,\n    f: (a1: A1, a2: A2) => R): Eval<R> {\n\n    const fl: Eval<any[]> = Eval.sequence([fa1, fa2] as any[])\n    return fl.map(lst => f(lst[0], lst[1]))\n  }\n\n  /**\n   * Maps 3 `Eval` values by the mapping function, returning a new\n   * `Eval` reference that completes with the result of mapping that\n   * function to the successful values of the futures, or in failure in\n   * case either of them fails.\n   *\n   * ```typescript\n   * const fa1 = Eval.of(() => 1)\n   * const fa2 = Eval.of(() => 2)\n   * const fa3 = Eval.of(() => 3)\n   *\n   *\n   * // Yields Success(6)\n   * Eval.map3(fa1, fa2, fa3, (a, b, c) => a + b + c)\n   * ```\n   */\n  static map3<A1, A2, A3, R>(\n    fa1: Eval<A1>, fa2: Eval<A2>, fa3: Eval<A3>,\n    f: (a1: A1, a2: A2, a3: A3) => R): Eval<R> {\n\n    const fl: Eval<any[]> = Eval.sequence([fa1, fa2, fa3] as any[])\n    return fl.map(lst => f(lst[0], lst[1], lst[2]))\n  }\n\n  /**\n   * Maps 4 `Eval` values by the mapping function, returning a new\n   * `Eval` reference that completes with the result of mapping that\n   * function to the successful values of the futures, or in failure in\n   * case either of them fails.\n   *\n   * ```typescript\n   * const fa1 = Eval.of(() => 1)\n   * const fa2 = Eval.of(() => 2)\n   * const fa3 = Eval.of(() => 3)\n   * const fa4 = Eval.of(() => 4)\n   *\n   * // Yields Success(10)\n   * Eval.map4(fa1, fa2, fa3, fa4, (a, b, c, d) => a + b + c + d)\n   * ```\n   */\n  static map4<A1, A2, A3, A4, R>(\n    fa1: Eval<A1>, fa2: Eval<A2>, fa3: Eval<A3>, fa4: Eval<A4>,\n    f: (a1: A1, a2: A2, a3: A3, a4: A4) => R): Eval<R> {\n\n    const fl: Eval<any[]> = Eval.sequence([fa1, fa2, fa3, fa4] as any[])\n    return fl.map(lst => f(lst[0], lst[1], lst[2], lst[3]))\n  }\n\n  /**\n   * Maps 5 `Eval` values by the mapping function, returning a new\n   * `Eval` reference that completes with the result of mapping that\n   * function to the successful values of the futures, or in failure in\n   * case either of them fails.\n   *\n   * ```typescript\n   * const fa1 = Eval.of(() => 1)\n   * const fa2 = Eval.of(() => 2)\n   * const fa3 = Eval.of(() => 3)\n   * const fa4 = Eval.of(() => 4)\n   * const fa5 = Eval.of(() => 5)\n   *\n   * // Yields Success(15)\n   * Eval.map5(fa1, fa2, fa3, fa4, fa5,\n   *   (a, b, c, d, e) => a + b + c + d + e\n   * )\n   * ```\n   */\n  static map5<A1, A2, A3, A4, A5, R>(\n    fa1: Eval<A1>, fa2: Eval<A2>, fa3: Eval<A3>, fa4: Eval<A4>, fa5: Eval<A5>,\n    f: (a1: A1, a2: A2, a3: A3, a4: A4, a5: A5) => R): Eval<R> {\n\n    const fl: Eval<any[]> = Eval.sequence([fa1, fa2, fa3, fa4, fa5] as any[])\n    return fl.map(lst => f(lst[0], lst[1], lst[2], lst[3], lst[4]))\n  }\n\n  /**\n   * Maps 6 `Eval` values by the mapping function, returning a new\n   * `Eval` reference that completes with the result of mapping that\n   * function to the successful values of the futures, or in failure in\n   * case either of them fails.\n   *\n   * ```typescript\n   * const fa1 = Eval.of(() => 1)\n   * const fa2 = Eval.of(() => 2)\n   * const fa3 = Eval.of(() => 3)\n   * const fa4 = Eval.of(() => 4)\n   * const fa5 = Eval.of(() => 5)\n   * const fa6 = Eval.of(() => 6)\n   *\n   * // Yields Success(21)\n   * Eval.map6(\n   *   fa1, fa2, fa3, fa4, fa5, fa6,\n   *   (a, b, c, d, e, f) => a + b + c + d + e + f\n   * )\n   * ```\n   */\n  static map6<A1, A2, A3, A4, A5, A6, R>(\n    fa1: Eval<A1>, fa2: Eval<A2>, fa3: Eval<A3>, fa4: Eval<A4>, fa5: Eval<A5>, fa6: Eval<A6>,\n    f: (a1: A1, a2: A2, a3: A3, a4: A4, a5: A5, a6: A6) => R): Eval<R> {\n\n    const fl: Eval<any[]> = Eval.sequence([fa1, fa2, fa3, fa4, fa5, fa6] as any[])\n    return fl.map(lst => f(lst[0], lst[1], lst[2], lst[3], lst[4], lst[5]))\n  }\n}\n\n/**\n * `Now` is an internal `Eval` state that wraps any strict\n * value in an `Eval` reference. Returned by [[Eval.now]].\n *\n * @private\n */\nclass Now<A> extends Eval<A> {\n  readonly _tag: \"now\" = \"now\"\n\n  /**\n   * @param value is the value that's going to be returned\n   * when `get()` is called.\n   */\n  constructor(public readonly value: A) { super() }\n\n  get(): A { return this.value }\n  toString(): string { return `Eval.now(${JSON.stringify(this.value)})` }\n}\n\n/**\n * Reusable reference, to use in {@link Eval.unit}.\n *\n * @private\n */\nconst evalUnitRef: Now<void> = new Now(undefined)\n\n/**\n * `Once` is an internal `Eval` state that executes the given `thunk`\n * only once, upon calling `get()` and then memoize its result for\n * subsequent invocations.\n *\n * Returned by [[Eval.once]].\n *\n * @private\n */\nclass Once<A> extends Eval<A> {\n  readonly _tag: \"once\" = \"once\"\n\n  private _thunk: () => A\n  private _cache?: Throwable | A\n  private _isError?: boolean\n\n  constructor(thunk: () => A) {\n    super()\n    this._thunk = thunk\n  }\n\n  get(): A {\n    if (this._thunk) {\n      try {\n        this._cache = this._thunk()\n        this._isError = false\n      } catch (e) {\n        this._cache = e\n        this._isError = true\n      }\n      // GC purposes\n      delete this._thunk\n    }\n\n    if (this._isError) throw this._cache\n    return this._cache as A\n  }\n\n  toString(): string { return `Eval.once([thunk])` }\n}\n\n/**\n * `Always` is an internal `Eval` state that executes the given `thunk`\n * every time the call to `get()` happens. Returned by [[Eval.always]].\n *\n * @private\n */\nclass Always<A> extends Eval<A> {\n  readonly _tag: \"always\" = \"always\"\n\n  constructor(thunk: () => A) {\n    super()\n    this.get = thunk\n  }\n\n  toString(): string { return `Eval.always([thunk])` }\n}\n\n/**\n * `Suspend` is an internal `Eval` state that represents a factory of\n * `Eval` values. Returned by [[Eval.suspend]].\n *\n * @private\n */\nclass Suspend<A> extends Eval<A> {\n  readonly _tag: \"suspend\" = \"suspend\"\n\n  constructor(public readonly thunk: () => Eval<A>) { super() }\n  toString(): string { return `Eval.suspend([thunk])` }\n}\n\n/**\n * `FlatMap` is an internal `Eval` state that represents a\n * [[Eval.flatMap .flatMap]], [[Eval.map .map]] operations,\n * all of them being expressed with this state.\n *\n * @private\n */\nclass FlatMap<A, B> extends Eval<B> {\n  readonly _tag: \"flatMap\" = \"flatMap\"\n\n  constructor(\n    public readonly source: Eval<A>,\n    public readonly f: (a: A) => Eval<B>) { super() }\n\n  toString(): string {\n    return `Eval#FlatMap(${String(this.source)}, [function])`\n  }\n}\n\n/**\n * Type enumerating the type classes implemented by `Eval`.\n */\nexport type EvalTypes = Monad<\"funfix/eval\">\n\n/**\n * Type-class implementations, compatible with the `static-land`\n * specification.\n */\nexport const EvalModule: EvalTypes = {\n  // Functor\n  map: <A, B>(f: (a: A) => B, fa: Eval<A>) =>\n    fa.map(f),\n  // Apply\n  ap: <A, B>(ff: Eval<(a: A) => B>, fa: Eval<A>): Eval<B> =>\n    fa.ap(ff),\n  // Applicative\n  of: Eval.pure,\n  // Chain\n  chain: <A, B>(f: (a: A) => Eval<B>, fa: Eval<A>): Eval<B> =>\n    fa.flatMap(f),\n  // ChainRec\n  chainRec: <A, B>(f: <C>(next: (a: A) => C, done: (b: B) => C, a: A) => Eval<C>, a: A): Eval<B> =>\n    Eval.tailRecM(a, a => f(Either.left as any, Either.right as any, a))\n}\n\n// Registers Fantasy-Land compatible symbols\ncoreInternals.fantasyLandRegister(Eval, EvalModule)\n\n/** @hidden */\ntype Current = Eval<any>\n/** @hidden */\ntype Bind = ((a: any) => Eval<any>)\n/** @hidden */\ntype CallStack = Array<Bind>\n\n/** @hidden */\nfunction _popNextBind(bFirst: Bind | null, bRest: CallStack | null): Bind | undefined | null {\n  if (bFirst) return bFirst\n  if (bRest && bRest.length > 0) return bRest.pop()\n  return null\n}\n\n/** @hidden */\nfunction evalRunLoop<A>(start: Eval<A>): A {\n  let current: Current = start\n  let bFirst: Bind | null = null\n  let bRest: CallStack | null = null\n\n  while (true) {\n    switch (current._tag) {\n      case \"now\":\n        const now = current as Now<A>\n        const bind = _popNextBind(bFirst, bRest)\n        if (!bind) return now.value\n        bFirst = null\n        current = bind(now.value)\n        break\n\n      case \"always\":\n      case \"once\":\n        current = new Now(current.get())\n        break\n\n      case \"suspend\":\n        current = (current as Suspend<A>).thunk()\n        break\n\n      case \"flatMap\":\n        if (bFirst) {\n          if (!bRest) bRest = []\n          bRest.push(bFirst)\n        }\n        const fm = current as FlatMap<any, any>\n        bFirst = fm.f\n        current = fm.source\n        break\n    }\n  }\n}\n\n/**\n * Implementation for `Eval.sequence`.\n * @hidden\n */\nfunction evalSequence<A>(list: Eval<A>[] | Iterable<Eval<A>>): Eval<A[]> {\n  return Eval.of(() => iteratorOf(list))\n    .flatMap(cursor => evalSequenceLoop([], cursor))\n}\n\n/**\n * Recursive loop that goes through the given `cursor`, element by\n * element, gathering the results of all generated `Eval` elements.\n *\n * @hidden\n */\nfunction evalSequenceLoop<A>(acc: A[], cursor: IteratorLike<Eval<A>>): Eval<A[]> {\n  while (true) {\n    const elem = cursor.next()\n    const isDone = elem.done\n\n    if (elem.value) {\n      const io: Eval<A> = elem.value\n      return io.flatMap(a => {\n        acc.push(a)\n        if (isDone) return Eval.pure(acc)\n        return evalSequenceLoop(acc, cursor)\n      })\n    } else {\n      /* istanbul ignore else */\n      if (isDone) return Eval.pure(acc)\n    }\n  }\n}\n","/*!\n * Copyright (c) 2017-2018 by The Funfix Project Developers.\n * Some rights reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { HK, Monad } from \"funland\"\nimport {\n  Either,\n  Try,\n  Success,\n  Failure,\n  Throwable,\n  TimeoutError,\n  Option, Some, None,\n  coreInternals\n} from \"funfix-core\"\n\nimport {\n  ICancelable,\n  Cancelable,\n  StackedCancelable,\n  Scheduler,\n  Future, ExecutionModel,\n  execInternals, Duration\n} from \"funfix-exec\"\n\nimport {\n  IteratorLike,\n  iteratorOf\n} from \"./internals\"\n\n/**\n * `IO` represents a specification for a possibly lazy or\n * asynchronous computation, which when executed will produce an `A`\n * as a result, along with possible side-effects.\n *\n * Compared with Funfix's\n * [Future](https://funfix.org/api/exec/classes/future.html) (see\n * [funfix-exec](https://funfix.org/api/exec/)) or JavaScript's\n * [Promise](https://promisesaplus.com/),\n * `IO` does not represent a running computation or a value detached\n * from time, as `IO` does not execute anything when working with its\n * builders or operators and it does not submit any work into the\n * [Scheduler](https://funfix.org/api/exec/classes/scheduler.html) or any\n * run-loop for execution, the execution eventually\n * taking place only after {@link IO.run} is called and not before\n * that.\n *\n * In order to understand `IO`, here's the design space:\n *\n * |                  | Strict                     | Lazy                               |\n * |------------------|:--------------------------:|:----------------------------------:|\n * | **Synchronous**  | `A`                        | `() => A`                          |\n * |                  |                            | [Eval&lt;A&gt;]{@link Eval}        |\n * | **Asynchronous** | `(Try<A> => void) => void` | `() => ((Try<A> => void) => void)` |\n * |                  | `Future<A>` / `Promise`    | [IO&lt;A&gt;]{@link IO}            |\n *\n * JavaScript is a language (and runtime) that's strict by default,\n * meaning that expressions are evaluated immediately instead of\n * being evaluated on a by-need basis, like in Haskell.\n *\n * So a value `A` is said to be strict. To turn an `A` value into a lazy\n * value, you turn that expression into a parameterless function of\n * type `() => A`, also called a \"thunk\".\n *\n * A [Future](https://funfix.org/api/exec/classes/future.html) is a\n * value that's produced by an asynchronous process, but it is said\n * to have strict behavior, meaning that when you receive a `Future`\n * reference, whatever process that's supposed to complete the\n * `Future` has probably started already. This goes for\n * [JavaScript's Promise](https://promisesaplus.com) as well.\n *\n * But there are cases where we don't want strict values, but lazily\n * evaluated ones. In some cases we want functions, or\n * `Future`-generators. Because we might want better handling of\n * parallelism, or we might want to suspend *side effects*. As\n * without suspending *side effects* we don't have *referential\n * transparency*, which really helps with reasoning about the code,\n * being the essence of *functional programming*.\n *\n * This `IO` type is thus the complement to `Future`, a lazy, lawful\n * monadic type that can describe any side effectful action, including\n * asynchronous ones, also capable of suspending side effects.\n *\n * ## Getting Started\n *\n * To build an `IO` from a parameterless function returning a value\n * (a thunk), we can use `IO.of`:\n *\n * ```typescript\n * const hello = IO.of(() => \"Hello \")\n * const world = IO.of(() => \"World!\")\n * ```\n *\n * Nothing gets executed yet, as `IO` is lazy, nothing executes\n * until you trigger [run]{@link IO.run} on it.\n *\n * To combine `IO` values we can use `map` and `flatMap`, which\n * describe sequencing and this time is in a very real sense because\n * of the laziness involved:\n *\n * ```typescript\n * const sayHello = hello\n *   .flatMap(h => world.map(w => h + w))\n *   .map(console.info)\n * ```\n *\n * This `IO` reference will trigger a side effect on evaluation, but\n * not yet. To make the above print its message:\n *\n * ```typescript\n * const f: Future<void> = sayHello.run()\n *\n * //=> Hello World!\n * ```\n *\n * The returned type is a\n * [Future](https://funfix.org/api/exec/classes/future.html), a value\n * that can be completed already or might be completed at some point\n * in the future, once the running asynchronous process finishes.\n * It's the equivalent of JavaScript's `Promise`, only better and\n * cancelable, see next topic.\n *\n * ## Laziness\n *\n * The fact that `IO` is lazy, whereas `Future` and `Promise` are not\n * has real consequences. For example with `IO` you can do this:\n *\n * ```typescript\n * function retryOnFailure<A>(times: number, io: IO<A>): IO<A> {\n *   return source.recoverWith(err => {\n *     // No more retries left? Re-throw error:\n *     if (times <= 0) return IO.raise(err)\n *     // Recursive call, yes we can!\n *     return retryOnFailure(times - 1, io)\n *       // Adding 500 ms delay for good measure\n *       .delayExecution(500)\n *   })\n * }\n * ```\n *\n * `Future` being a strict value-wannabe means that the actual value\n * gets \"memoized\" (means cached), however `IO` is basically a function\n * that can be repeated for as many times as you want. `IO` can also\n * do memoization of course:\n *\n * ```typescript\n * io.memoize()\n * ```\n *\n * The difference between this and just calling `run()` is that\n * `memoize()` still returns an `IO` and the actual memoization\n * happens on the first `run()` (with idempotency guarantees of\n * course).\n *\n * But here's something else that `Future` or your favorite\n * `Promise`-like data type cannot do:\n *\n * ```typescript\n * io.memoizeOnSuccess()\n * ```\n *\n * This keeps repeating the computation for as long as the result is a\n * failure and caches it only on success. Yes we can!\n *\n * ### Parallelism\n *\n * Because of laziness, invoking {@link IO.sequence} will not work like\n * it does for `Future.sequence` or `Promise.all`, the given `IO` values\n * being evaluated one after another, in *sequence*, not in *parallel*.\n * If you want parallelism, then you need to use {@link IO.gather} and\n * thus be explicit about it.\n *\n * This is great because it gives you the possibility of fine tuning the\n * execution. For example, say you want to execute things in parallel,\n * but with a maximum limit of 30 tasks being executed in parallel.\n * One way of doing that is to process your list in batches.\n *\n * This sample assumes you have [lodash](https://lodash.com/) installed,\n * for manipulating our array:\n *\n * ```typescript\n * import * as _ from \"lodash\"\n * import { IO } from \"funfix\"\n *\n * // Some array of IOs, you come up with something good :-)\n * const list: IO<string>[] = ???\n *\n * // Split our list in chunks of 30 items per chunk,\n * // this being the maximum parallelism allowed\n * const chunks = _.chunks(list, 30)\n * // Specify that each batch should process stuff in parallel\n * const batchedIOs = _.map(chunks, chunk => IO.gather(chunk))\n * // Sequence the batches\n * const allBatches = IO.sequence(batchedIOs)\n *\n * // Flatten the result, within the context of IO\n * const all: IO<string[]> =\n *   allBatches.map(batches => _.flatten(batches))\n * ```\n *\n * Note that the built `IO` reference is just a specification at this point,\n * or you can view it as a function, as nothing has executed yet, you need\n * to call {@link IO.run .run} explicitly.\n *\n * ## Cancellation\n *\n * The logic described by an `IO` task could be cancelable, depending\n * on how the `IO` gets built. This is where the `IO`-`Future`\n * symbiosis comes into play.\n *\n * Futures can also be canceled, in case the described computation can\n * be canceled. When describing `IO` tasks with `IO.of` nothing can be\n * cancelled, since there's nothing about a plain function that you\n * can cancel, but, we can build cancelable tasks with\n * {@link IO.async}:\n *\n * ```typescript\n * import { Cancelable, Success, IO } from \"funfix\"\n *\n * const delayedHello = IO.async((scheduler, callback) => {\n *   const task = scheduler.scheduleOnce(1000, () => {\n *     console.info(\"Delayed Hello!\")\n *     // Signaling successful completion\n *     // (\"undefined\" inhabits type \"void\")\n *     callback(Success(undefined))\n *   })\n *\n *   return Cancelable.of(() => {\n *     console.info(\"Cancelling!\")\n *     task.cancel()\n *   })\n * })\n * ```\n *\n * The sample above prints a message with a delay, where the delay\n * itself is scheduled with the injected `Scheduler`. The `Scheduler`\n * is in fact an optional parameter to {@link IO.run} and if one\n * isn't explicitly provided, then `Scheduler.global` is assumed.\n *\n * This action can be cancelled, because it specifies cancellation\n * logic. If we wouldn't return an explicit `Cancelable` there,\n * then cancellation wouldn't work. But for this `IO` reference\n * it does:\n *\n * ```typescript\n * // Triggering execution, which sends a task to execute by means\n * // of JavaScript's setTimeout (under the hood):\n * const f: Future<void> = delayedHello.run()\n *\n * // If we change our mind before the timespan has passed:\n * f.cancel()\n * ```\n *\n * Also, given an `IO` task, we can specify actions that need to be\n * triggered in case of cancellation:\n *\n * ```typescript\n * const io = IO.of(() => console.info(\"Hello!\"))\n *   .executeForked()\n *\n * io.doOnCancel(IO.of(() => {\n *   console.info(\"A cancellation attempt was made!\")\n * })\n *\n * const f: Future<void> = io.run()\n *\n * // Note that in this case cancelling the resulting Future\n * // will not stop the actual execution, since it doesn't know\n * // how, but it will trigger our on-cancel callback:\n *\n * f.cancel()\n * //=> A cancellation attempt was made!\n * ```\n *\n * ## Note on the ExecutionModel\n *\n * `IO` is conservative in how it introduces async boundaries.\n * Transformations like `map` and `flatMap` for example will default\n * to being executed on the current call stack on which the\n * asynchronous computation was started. But one shouldn't make\n * assumptions about how things will end up executed, as ultimately\n * it is the implementation's job to decide on the best execution\n * model. All you are guaranteed is asynchronous execution after\n * executing `run`.\n *\n * Currently the default `ExecutionModel` specifies batched execution\n * by default and `IO` in its evaluation respects the injected\n * `ExecutionModel`. If you want a different behavior, you need to\n * execute the `IO` reference with a different scheduler.\n *\n * In order to configure a different execution model, this config\n * can be injected by means of a custom scheduler:\n *\n * ```typescript\n * import { Scheduler, ExecutionModel } from \"funfix\"\n *\n * const ec = Scheduler.global.get()\n *   .withExecutionModel(ExecutionModel.alwaysAsync())\n *\n * // ...\n * io.run(ec)\n * ```\n *\n * Or you can configure an `IO` reference to execute with a certain\n * execution model that overrides the configuration of the injected\n * scheduler, by means of {@link IO.executeWithModel}:\n *\n * ```typescript\n * io.executeWithModel(ExecutionModel.batched(256))\n * ```\n *\n * ## Versus Eval\n *\n * For dealing with lazy evaluation, the other alternative is\n * the {@link Eval} data type.\n *\n * Differences between `Eval` and `IO`:\n *\n * 1. `IO` is capable of describing asynchronous computations as well\n * 2. `IO` is capable of error handling (it implements `MonadError`),\n *    whereas `Eval` does not provide error handling capabilities,\n *    being meant to be used for pure expressions (it implements\n *    `Comonad`, which is incompatible with `MonadError`)\n * 3. You cannot rely on `IO` to produce a value immediately, since\n *    we cannot block threads on top of JavaScript engines\n *\n * So if you need error handling capabilities\n * (i.e. `MonadError<Throwable, ?>`), or if you need to describe\n * asynchronous processes, then `IO` is for you. {@link Eval}\n * is a simpler data type with the sole purpose of controlling the\n * evaluation of expressions (i.e. strict versus lazy).\n *\n * ## Credits\n *\n * This type is inspired by `cats.effect.IO` from\n * {@link http://typelevel.org/cats/|Typelevel Cats},\n * by `monix.eval.Task` from {@link https://monix.io|Monix}, by\n * `scalaz.effect.IO` from [Scalaz](https://github.com/scalaz/scalaz),\n * which are all inspired by Haskell's `IO` data type.\n *\n * @final\n */\nexport class IO<A> implements HK<\"funfix/io\", A> {\n  /**\n   * Triggers the asynchronous execution.\n   *\n   * Without invoking `run` on a `IO`, nothing gets evaluated, as an\n   * `IO` has lazy behavior.\n   *\n   * ```typescript\n   * // Describing a side effect\n   * const io = IO.of(() => console.log(\"Hello!\"))\n   *   // Delaying it for 1 second, for didactical purposes\n   *   .delayExecution(1000)\n   *\n   * // Nothing executes until we call run on it, which gives\n   * // us a Future in return:\n   * const f: Future<void> = io.run()\n   *\n   * // The given Future is cancelable, in case the logic\n   * // decribed by our IO is cancelable, so we can do this:\n   * f.cancel()\n   * ```\n   *\n   * Note that `run` takes a\n   * [Scheduler](https://funfix.org/api/exec/classes/scheduler.html)\n   * as an optional parameter and if one isn't provided, then the\n   * default scheduler gets used. The `Scheduler` is in charge\n   * of scheduling asynchronous boundaries, executing tasks\n   * with a delay (e.g. `setTimeout`) or of reporting failures\n   * (with `console.error` by default).\n   *\n   * Also see {@link IO.runOnComplete} for a version that takes a\n   * callback as parameter.\n   *\n   * @return a `Future` that will eventually complete with the\n   *         result produced by this `IO` on evaluation\n   */\n  run(ec: Scheduler = Scheduler.global.get()): Future<A> {\n    return taskToFutureRunLoop(this, ec)\n  }\n\n  /**\n   * Triggers the asynchronous execution.\n   *\n   * Without invoking `run` on a `IO`, nothing gets evaluated, as an\n   * `IO` has lazy behavior.\n   *\n   * `runComplete` starts the evaluation and takes a callback which\n   * will be triggered when the computation is complete.\n   *\n   * Compared with JavaScript's `Promise.then` the provided callback\n   * is a function that receives a\n   * [Try](https://funfix.org/api/core/classes/try.html) value, a data\n   * type which is what's called a \"logical disjunction\", or a \"tagged\n   * union type\", a data type that can represent both successful\n   * results and failures. This is because in Funfix we don't work\n   * with `null`.\n   *\n   * Also the returned value is an\n   * [ICancelable](https://funfix.org/api/exec/interfaces/icancelable.html)\n   * reference, which can be used to cancel the running computation,\n   * in case the logic described by our `IO` is cancelable (note that\n   * some procedures cannot be cancelled, it all depends on how the\n   * `IO` value was described, see {@link IO.async} for how cancelable\n   * `IO` values can be built).\n   *\n   * Example:\n   *\n   * ```typescript\n   * // Describing a side effect\n   * const io = IO.of(() => console.log(\"Hello!\"))\n   *   .delayExecution(1000)\n   *\n   * // Nothing executes until we explicitly run our `IO`:\n   * const c: ICancelable = io.runOnComplete(r =>\n   *   r.fold(\n   *     err => console.error(err),\n   *     _ => console.info(\"Done!\")\n   *   ))\n   *\n   * // In case we change our mind and the logic described by\n   * // our `IO` is cancelable, we can cancel it:\n   * c.cancel()\n   * ```\n   *\n   * Note that `runOnComplete` takes a\n   * [Scheduler](https://funfix.org/api/exec/classes/scheduler.html)\n   * as an optional parameter and if one isn't provided, then the\n   * default scheduler gets used. The `Scheduler` is in charge\n   * of scheduling asynchronous boundaries, executing tasks\n   * with a delay (e.g. `setTimeout`) or of reporting failures\n   * (with `console.error` by default).\n   *\n   * Also see {@link IO.run} for a version that returns a `Future`,\n   * which might be easier to work with, especially since a `Future`\n   * is `Promise`-like.\n   *\n   * @param cb is the callback that will be eventually called with\n   *        the final result, or error, when the evaluation completes\n   *\n   * @param ec is the scheduler that controls the triggering of\n   *        asynchronous boundaries (e.g. `setTimeout`)\n   *\n   * @return a cancelable action that can be triggered to cancel\n   *         the running computation, assuming that the implementation\n   *         of the source `IO` can be cancelled\n   */\n  runOnComplete(\n    cb: (result: Try<A>) => void,\n    ec: Scheduler = Scheduler.global.get()): ICancelable {\n\n    const ref = ioGenericRunLoop(this, ec, null, cb, null, null, null)\n    return ref || Cancelable.empty()\n  }\n\n  /**\n   * Handle errors by lifting results into `Either` values.\n   *\n   * If there's an error, then a `Left` value will be signaled. If\n   * there is no error, then a `Right` value will be signaled instead.\n   *\n   * The returned type is an\n   * [Either](https://funfix.org/api/core/classes/either.html) value,\n   * which is what's called a \"logical disjunction\" or a \"tagged union\n   * type\", representing a choice between two values, in this case\n   * errors on the \"Left\" and successful results on the \"Right\".\n   *\n   * ```typescript\n   * // Describing an IO that can fail on execution:\n   * const io: IO<number> = IO.of(() => {\n   *   const n = Math.random() * 1000\n   *   const m = n & n // to integer\n   *   if (m % 2) throw new Error(\"No odds please!\")\n   *   return m\n   * })\n   *\n   * // By using attempt() we can observe and use errors\n   * // in `map` and `flatMap` transformations:\n   * io.attempt().map(either =>\n   *   either.fold(\n   *     err => \"odd\",\n   *     val => \"even\"\n   *   ))\n   * ```\n   *\n   * For other error handling capabilities, see {@link IO.recoverWith}\n   * and {@link IO.transformWith}.\n   */\n  attempt(): IO<Either<Throwable, A>> {\n    return this.transform(\n      _ => Either.left<Throwable, A>(_),\n      Either.right)\n  }\n\n  /**\n   * Introduces an asynchronous boundary at the current stage in the\n   * asynchronous processing pipeline (after the source has been\n   * evaluated).\n   *\n   * Consider the following example:\n   *\n   * ```typescript\n   * const readPath: () => \"path/to/file\"\n   *\n   * const io = IO.of(readPath)\n   *   .asyncBoundary()\n   *   .map(fs.readFileSync)\n   * ```\n   *\n   * Between reading the path and then reading the file from that\n   * path, we schedule an async boundary (it usually happens with\n   * JavaScript's `setTimeout` under the hood).\n   *\n   * This is equivalent with:\n   *\n   * ```typescript\n   * self.flatMap(a => IO.shift(ec).map(_ => a))\n   *\n   * // ... or ...\n   *\n   * self.forEffect(IO.shift(ec))\n   * ```\n   *\n   * Also see {@link IO.shift} and {@link IO.fork}.\n   *\n   * @param ec is an optional `Scheduler` implementation that can\n   *        be used for scheduling the async boundary, however if\n   *        not specified, the `IO`'s default scheduler (the one\n   *        passed to `run()`) gets used\n   */\n  asyncBoundary(ec?: Scheduler): IO<A> {\n    return this.flatMap(a => IO.shift(ec).map(() => a))\n  }\n\n  /**\n   * Alias for {@link IO.flatMap .flatMap}.\n   */\n  chain<B>(f: (a: A) => IO<B>): IO<B> {\n    return this.flatMap(f)\n  }\n\n  /**\n   * Delays the evaluation of this `IO` by the specified duration.\n   *\n   * ```typescript\n   * const fa = IO.of(() => \"Hello\")\n   *\n   * // Delays the evaluation by 1 second\n   * fa.delayExecution(1000)\n   * ```\n   *\n   * @param delay is the duration to wait before signaling the\n   *        final result\n   */\n  delayExecution(delay: number | Duration): IO<A> {\n    return IO.delayedTick(delay).flatMap(() => this)\n  }\n\n  /**\n   * Delays signaling the result of this `IO` on evaluation by the\n   * specified duration.\n   *\n   * It works for successful results:\n   *\n   * ```typescript\n   * const fa = IO.of(() => \"Alex\")\n   *\n   * // Delays the signaling by 1 second\n   * fa.delayResult(1000)\n   * ```\n   *\n   * And for failures as well:\n   *\n   * ```typescript\n   * Future.raise(new TimeoutError()).delayResult(1000)\n   * ```\n   *\n   * @param delay is the duration to wait before signaling the\n   *        final result\n   */\n  delayResult(delay: number | Duration): IO<A> {\n    return this.transformWith(\n      err => IO.delayedTick(delay).flatMap(() => IO.raise(err)),\n      a => IO.delayedTick(delay).map(() => a)\n    )\n  }\n\n  /**\n   * Returns a new `IO` in which `f` is scheduled to be run on\n   * completion. This would typically be used to release any\n   * resources acquired by this `IO`.\n   *\n   * The returned `IO` completes when both the source and the task\n   * returned by `f` complete.\n   *\n   * NOTE: The given function is only called when the task is\n   * complete.  However the function does not get called if the task\n   * gets canceled. Cancellation is a process that's concurrent with\n   * the execution of a task and hence needs special handling.\n   *\n   * See {@link IO.doOnCancel} for specifying a callback to call on\n   * canceling a task.\n   */\n  doOnFinish(f: (e: Option<Throwable>) => IO<void>): IO<A> {\n    return this.transformWith(\n      e => f(Some(e)).flatMap(() => IO.raise(e)),\n      a => f(None).map(() => a)\n    )\n  }\n\n  /**\n   * Returns a new `IO` that will mirror the source, but that will\n   * execute the given `callback` if the task gets canceled before\n   * completion.\n   *\n   * This only works for premature cancellation. See\n   * {@link IO.doOnFinish} for triggering callbacks when the\n   * source finishes.\n   *\n   * @param callback is the `IO` value to execute if the task gets\n   *        canceled prematurely\n   */\n  doOnCancel(callback: IO<void>): IO<A> {\n    return IO.asyncUnsafe<A>((ctx, cb) => {\n      const ec = ctx.scheduler\n      ec.trampoline(() => {\n        const conn = ctx.connection\n        conn.push(Cancelable.of(() => callback.run(ec)))\n        IO.unsafeStart(this, ctx, ioSafeCallback(ec, conn, cb))\n      })\n    })\n  }\n\n  /**\n   * Ensures that an asynchronous boundary happens before the\n   * execution, managed by the provided scheduler.\n   *\n   * Alias for {@link IO.fork}.\n   *\n   * Calling this is equivalent with:\n   *\n   * ```typescript\n   * IO.shift(ec).flatMap(_ => self)\n   *\n   * // ... or ...\n   *\n   * IO.shift(ec).followedBy(self)\n   * ```\n   *\n   * See {@link IO.fork}, {@link IO.asyncBoundary} and {@link IO.shift}.\n   */\n  executeForked(ec?: Scheduler): IO<A> {\n    return IO.fork(this, ec)\n  }\n\n  /**\n   * Override the `ExecutionModel` of the default scheduler.\n   *\n   * ```typescript\n   * import { ExecutionModel } from \"funfix\"\n   *\n   * io.executeWithModel(ExecutionModel.alwaysAsync())\n   * ```\n   */\n  executeWithModel(em: ExecutionModel): IO<A> {\n    return IO.asyncUnsafe<A>((ctx, cb) => {\n      const ec = ctx.scheduler.withExecutionModel(em)\n      const ctx2 = new IOContext(ec, ctx.connection, ctx.options)\n      ec.trampoline(() => IO.unsafeStart(this, ctx2, cb))\n    })\n  }\n\n  /**\n   * Returns a new `IO` that upon evaluation will execute with the\n   * given set of {@link IOOptions}, allowing for tuning the run-loop.\n   *\n   * This allows for example making run-loops \"auto-cancelable\",\n   * an option that's off by default due to safety concerns:\n   *\n   * ```typescript\n   * io.executeWithOptions({\n   *   autoCancelableRunLoops: true\n   * })\n   * ```\n   */\n  executeWithOptions(set: IOOptions): IO<A> {\n    return IO.asyncUnsafe<A>((ctx, cb) => {\n      const ec = ctx.scheduler\n      const ctx2 = new IOContext(ec, ctx.connection, set)\n      ec.trampoline(() => IO.unsafeStart(this, ctx2, cb))\n    })\n  }\n\n  /**\n   * Creates a new `IO` by applying a function to the successful\n   * result of the source, and returns a new instance equivalent to\n   * the result of the function.\n   *\n   * ```typescript\n   * const rndInt = IO.of(() => {\n   *   const nr = Math.random() * 1000000\n   *   return nr & nr\n   * })\n   *\n   * const evenInt = () =>\n   *   rndInt.flatMap(int => {\n   *     if (i % 2 == 0)\n   *       return IO.now(i)\n   *     else // Retry until we have an even number!\n   *       return evenInt()\n   *   })\n   * ```\n   */\n  flatMap<B>(f: (a: A) => IO<B>): IO<B> {\n    return new IOFlatMap(this, f)\n  }\n\n  /**\n   * `Applicative` apply operator.\n   *\n   * Resembles {@link map}, but the passed mapping function is\n   * lifted in the `Either` context.\n   */\n  ap<B>(ff: IO<(a: A) => B>): IO<B> {\n    return ff.flatMap(f => this.map(f))\n  }\n\n  /**\n   * Sequentially compose two `IO` actions, discarding any value\n   * produced by the first.\n   *\n   * So this:\n   *\n   * ```typescript\n   * ioA.followedBy(ioB)\n   * ```\n   *\n   * Is equivalent with this:\n   *\n   * ```typescript\n   * ioA.flatMap(_ => fb)\n   * ```\n   */\n  followedBy<B>(fb: IO<B>): IO<B> {\n    return this.flatMap(() => fb)\n  }\n\n  /**\n   * Returns a new `IO` that upon evaluation will execute the given\n   * function for the generated element, transforming the source into\n   * an `IO<void>`.\n   */\n  forEach(cb: (a: A) => void): IO<void> {\n    return this.map(cb)\n  }\n\n  /**\n   * Sequentially compose two actions, discarding any value\n   * produced by the second.\n   *\n   * So this:\n   *\n   * ```typescript\n   * ioA.forEffect(ioB)\n   * ```\n   *\n   * Is equivalent with this:\n   *\n   * ```typescript\n   * ioA.flatMap(a => ioB.map(_ => a))\n   * ```\n   */\n  forEffect<B>(fb: IO<B>): IO<A> {\n    return this.flatMap(a => fb.map(() => a))\n  }\n\n  /**\n   * Returns a new `IO` that applies the mapping function to the\n   * successful result emitted by the source.\n   *\n   * ```typescript\n   * IO.now(111).map(_ => _ * 2).get() // 222\n   * ```\n   *\n   * Note there's a correspondence between `flatMap` and `map`:\n   *\n   * ```typescript\n   * fa.map(f) <-> fa.flatMap(x => IO.pure(f(x)))\n   * ```\n   */\n  map<B>(f: (a: A) => B): IO<B> {\n    return new IOFlatMap(this, (a: A) => IO.now(f(a)))\n  }\n\n  /**\n   * Memoizes (caches) the result of the source `IO` and reuses it on\n   * subsequent invocations of `run`.\n   *\n   * The resulting task will be idempotent, meaning that\n   * evaluating the resulting task multiple times will have the\n   * same effect as evaluating it once.\n   *\n   * @see {@link IO.memoizeOnSuccess} for a version that only caches\n   *     successful results.\n   */\n  memoize(): IO<A> {\n    switch (this._tag) {\n      case \"pure\":\n        return this\n      case \"always\":\n        const always = (this as any) as IOAlways<A>\n        return new IOOnce(always.thunk, false)\n      case \"memoize\":\n        const mem = (this as any) as IOMemoize<A>\n        if (!mem.onlySuccess) return mem\n        return new IOMemoize(this, false)\n      default: // flatMap | async\n        return new IOMemoize(this, false)\n    }\n  }\n\n  /**\n   * Memoizes (caches) the successful result of the source task\n   * and reuses it on subsequent invocations of `run`.\n   * Thrown exceptions are not cached.\n   *\n   * The resulting task will be idempotent, but only if the\n   * result is successful.\n   *\n   * @see {@link IO.memoize} for a version that caches both successful\n   *     results and failures\n   */\n  memoizeOnSuccess(): IO<A> {\n    switch (this._tag) {\n      case \"pure\":\n      case \"once\":\n      case \"memoize\":\n        return this\n      case \"always\":\n        const always = (this as any) as IOAlways<A>\n        return new IOOnce(always.thunk, true)\n      default: // flatMap | async\n        return new IOMemoize(this, true)\n    }\n  }\n\n  /**\n   * Creates a new `IO` that will mirror the source on success,\n   * but on failure it will try to recover and yield a successful\n   * result by applying the given function `f` to the thrown error.\n   *\n   * This function is the equivalent of a `try/catch` statement,\n   * or the equivalent of {@link IO.map .map} for errors.\n   *\n   * ```typescript\n   * io.recover(err => {\n   *   console.error(err)\n   *   fallback\n   * })\n   * ```\n   */\n  recover<AA>(f: (e: Throwable) => AA): IO<A | AA> {\n    return this.recoverWith(a => IO.now(f(a)))\n  }\n\n  /**\n   * Creates a new `IO` that will mirror the source on success,\n   * but on failure it will try to recover and yield a successful\n   * result by applying the given function `f` to the thrown error.\n   *\n   * This function is the equivalent of a `try/catch` statement,\n   * or the equivalent of {@link IO.flatMap .flatMap} for errors.\n   *\n   * Note that because of `IO`'s laziness, this can describe retry\n   * loop:\n   *\n   * ```typescript\n   * function retryOnFailure<A>(times: number, io: IO<A>): IO<A> {\n   *   return source.recoverWith(err => {\n   *     // No more retries left? Re-throw error:\n   *     if (times <= 0) return IO.raise(err)\n   *     // Recursive call, yes we can!\n   *     return retryOnFailure(times - 1, io)\n   *       // Adding 500 ms delay for good measure\n   *       .delayExecution(500)\n   *   })\n   * }\n   * ```\n   */\n  recoverWith<AA>(f: (e: Throwable) => IO<AA>): IO<A | AA> {\n    return this.transformWith(f, IO.now as any)\n  }\n\n  /**\n   * Returns an `IO` that mirrors the source in case the result of\n   * the source is signaled within the required `after` duration\n   * on evaluation, otherwise it fails with a `TimeoutError`,\n   * cancelling the source.\n   *\n   * ```typescript\n   * const fa = IO.of(() => 1).delayResult(10000)\n   *\n   * // Will fail with a TimeoutError on run()\n   * fa.timeout(1000)\n   * ```\n   *\n   * @param after is the duration to wait until it triggers\n   *        the timeout error\n   */\n  timeout(after: number | Duration): IO<A> {\n    const fb = IO.raise(new TimeoutError(Duration.of(after).toString()))\n    return this.timeoutTo(after, fb)\n  }\n\n  /**\n   * Returns an `IO` value that mirrors the source in case the result\n   * of the source is signaled within the required `after` duration\n   * when evaluated (with `run()`), otherwise it triggers the\n   * execution of the given `fallback` after the duration has passed,\n   * cancelling the source.\n   *\n   * This is literally the implementation of {@link IO.timeout}:\n   *\n   * ```typescript\n   * const fa = IO.of(() => 1).delayResult(10000)\n   *\n   * fa.timeoutTo(1000, IO.raise(new TimeoutError()))\n   * ```\n   *\n   * @param after is the duration to wait until it triggers the `fallback`\n   * @param fallback is a fallback `IO` to timeout to\n   */\n  timeoutTo<AA>(after: number | Duration, fallback: IO<AA>): IO<A | AA> {\n    const other = IO.delayedTick(after).flatMap(() => fallback)\n    const lst: IO<A | AA>[] = [this, other]\n    return IO.firstCompletedOf(lst)\n  }\n\n  /**\n   * Creates a new `IO` by applying the 'success' function to the\n   * successful result of the source, or the 'error' function to the\n   * potential errors that might happen.\n   *\n   * This function is similar with {@link IO.map .map}, except that\n   * it can also transform errors and not just successful results.\n   *\n   * @param success is a function for transforming a successful result\n   * @param failure is a function for transforming failures\n   */\n  transform<R>(failure: (e: Throwable) => R, success: (a: A) => R): IO<R> {\n    return this.transformWith(\n      e => IO.now(failure(e)),\n      a => IO.now(success(a))\n    )\n  }\n\n  /**\n   * Creates a new `IO` by applying the 'success' function to the\n   * successful result of the source, or the 'error' function to the\n   * potential errors that might happen.\n   *\n   * This function is similar with {@link IO.flatMap .flatMap},\n   * except that it can also transform errors and not just successful\n   * results.\n   *\n   * @param success is a function for transforming a successful result\n   * @param failure is a function for transforming failures\n   */\n  transformWith<R>(failure: (e: Throwable) => IO<R>, success: (a: A) => IO<R>): IO<R> {\n    return new IOFlatMap(this, success, failure)\n  }\n\n  /**\n   * Identifies the `IO` reference type, useful for debugging and\n   * for pattern matching in the implementation.\n   *\n   * @hidden\n   */\n  readonly _tag!: \"pure\" | \"always\" | \"once\" | \"flatMap\" | \"async\" | \"memoize\"\n\n  // Implements HK<F, A>\n  /** @hidden */ readonly _URI!: \"funfix/io\"\n  /** @hidden */ readonly _A!: A\n\n  // Implements Constructor<T>\n  /** @hidden */ static readonly _Class: IO<any>\n\n  /**\n   * Promote a `thunk` function to an `IO`, catching exceptions in\n   * the process.\n   *\n   * Note that since `IO` is not memoized by global, this will\n   * recompute the value each time the `IO` is executed.\n   *\n   * ```typescript\n   * const io = IO.always(() => { console.log(\"Hello!\") })\n   *\n   * io.run()\n   * //=> Hello!\n   * io.run()\n   * //=> Hello!\n   * io.run()\n   * //=> Hello!\n   * ```\n   */\n  static always<A>(thunk: () => A): IO<A> {\n    return new IOAlways(thunk)\n  }\n\n  /**\n   * Create a `IO` from an asynchronous computation, which takes\n   * the form of a function with which we can register a callback.\n   *\n   * This can be used to translate from a callback-based API to a\n   * straightforward monadic version.\n   */\n  static async<A>(register: (ec: Scheduler, cb: (a: Try<A>) => void) => ICancelable | void): IO<A> {\n    return IO.asyncUnsafe<A>((ctx, cb) => {\n      const ec = ctx.scheduler\n      const conn = ctx.connection\n\n      // Forcing a light asynchronous boundary, otherwise\n      // stack overflows are possible\n      ec.trampoline(() => {\n        // Wrapping the callback in a safe implementation that\n        // provides idempotency guarantees and that pops from\n        // the given `StackedCancelable` at the right time\n        const safe = ioSafeCallback(ec, conn, cb)\n        try {\n          const ref = register(ec, safe)\n          // This `push` can be executed after `register`, even the\n          // `safe` callback gets executed immediately, because of\n          // the light async boundary in `ioSafeCallback`\n          conn.push(ref || Cancelable.empty())\n        } catch (e) {\n          safe(Failure(e))\n        }\n      })\n    })\n  }\n\n  /**\n   * Constructs a lazy [[IO]] instance whose result will be computed\n   * asynchronously.\n   *\n   * **WARNING:** Unsafe to use directly, only use if you know\n   * what you're doing. For building `IO` instances safely\n   * see {@link IO.async}.\n   *\n   * Rules of usage:\n   *\n   *  - the received `StackedCancelable` can be used to store\n   *    cancelable references that will be executed upon cancel;\n   *    every `push` must happen at the beginning, before any\n   *    execution happens and `pop` must happen afterwards\n   *    when the processing is finished, before signaling the\n   *    result\n   *  - before execution, an asynchronous boundary is recommended,\n   *    to avoid stack overflow errors, but can happen using the\n   *    scheduler's facilities for trampolined execution\n   *  - on signaling the result (`Success` or `Failure`),\n   *    another async boundary is necessary, but can also\n   *    happen with the scheduler's facilities for trampolined\n   *    execution (e.g. `Scheduler.trampoline`)\n   *\n   * **WARNING:** note that not only is this builder unsafe, but also\n   * unstable, as the {@link IORegister} callback type is exposing\n   * volatile internal implementation details. This builder is meant\n   * to create optimized asynchronous tasks, but for normal usage\n   * prefer {@link IO.async}.\n   */\n  static asyncUnsafe<A>(register: IORegister<A>): IO<A> {\n    return new IOAsync(register)\n  }\n\n  /**\n   * Promote a `thunk` function generating `IO` results to an `IO`\n   * of the same type.\n   *\n   * Alias for {@link IO.suspend}.\n   */\n  static defer<A>(thunk: () => IO<A>): IO<A> {\n    return IO.unit().flatMap(() => thunk())\n  }\n\n  /**\n   * Defers the creation of an `IO` by using the provided function,\n   * which has the ability to inject a needed `Scheduler`.\n   *\n   * Example:\n   *\n   * ```typescript\n   * function measureLatency<A>(source: IO<A>): IO<[A, Long]> {\n   *   return IO.deferAction<[A, Long]>(s => {\n   *     // We have our Scheduler, which can inject time, we\n   *     // can use it for side-effectful operations\n   *     const start = s.currentTimeMillis()\n   *\n   *     return source.map(a => {\n   *       const finish = s.currentTimeMillis()\n   *       return [a, finish - start]\n   *     })\n   *   })\n   * }\n   * ```\n   *\n   * @param f is the function that's going to be called when the\n   *        resulting `IO` gets evaluated\n   */\n  static deferAction<A>(f: (ec: Scheduler) => IO<A>): IO<A> {\n    return IO.asyncUnsafe<A>((ctx, cb) => {\n      const ec = ctx.scheduler\n      let ioa: IO<A>\n      try { ioa = f(ec) } catch (e) { ioa = IO.raise(e) }\n      ec.trampoline(() => IO.unsafeStart(ioa, ctx, cb))\n    })\n  }\n\n  /**\n   * Given a `thunk` that produces `Future` values, suspends it\n   * in the `IO` context, evaluating it on demand whenever the\n   * resulting `IO` gets evaluated.\n   *\n   * See {@link IO.fromFuture} for the strict version.\n   */\n  static deferFuture<A>(thunk: () => Future<A>): IO<A> {\n    return IO.suspend(() => IO.fromFuture(thunk()))\n  }\n\n  /**\n   * Wraps calls that generate `Future` results into `IO`, provided\n   * a callback with an injected `Scheduler`.\n   *\n   * This builder helps with wrapping `Future`-enabled APIs that need\n   * a `Scheduler` to work.\n   *\n   * @param f is the function that's going to be executed when the task\n   *        gets evaluated, generating the wrapped `Future`\n   */\n  static deferFutureAction<A>(f: (ec: Scheduler) => Future<A>): IO<A> {\n    return IO.deferAction(ec => IO.fromFuture(f(ec)))\n  }\n\n  /**\n   * Returns an `IO` that on evaluation will complete after the\n   * given `delay`.\n   *\n   * This can be used to do delayed execution. For example:\n   *\n   * ```typescript\n   * IO.delayedTick(1000).flatMap(_ =>\n   *   IO.of(() => console.info(\"Hello!\"))\n   * )\n   * ```\n   *\n   * @param delay is the duration to wait before signaling the tick\n   */\n  static delayedTick<A>(delay: number | Duration): IO<void> {\n    return IO.asyncUnsafe<void>((ctx, cb) => {\n      const conn = ctx.connection\n      const task = ctx.scheduler.scheduleOnce(delay, () => {\n        conn.pop()\n        cb(Try.unit())\n      })\n      conn.push(task)\n    })\n  }\n\n  /**\n   * Creates a race condition between multiple `IO` values, on\n   * evaluation returning the result of the first one that completes,\n   * cancelling the rest.\n   *\n   * ```typescript\n   * const failure = IO.raise(new TimeoutError()).delayResult(2000)\n   *\n   * // Will yield 1\n   * const fa1 = IO.of(() => 1).delayResult(1000)\n   * IO.firstCompletedOf([fa1, failure])\n   *\n   * // Will yield a TimeoutError\n   * const fa2 = IO.of(() => 1).delayResult(10000)\n   * IO.firstCompletedOf([fa2, failure])\n   * ```\n   *\n   * @param list is the list of `IO` values for which the\n   *        race is started\n   *\n   * @return a new `IO` that will evaluate to the result of the first\n   *         in the list to complete, the rest being cancelled\n   */\n  static firstCompletedOf<A>(list: IO<A>[] | Iterable<IO<A>>): IO<A> {\n    return ioListToFutureProcess(list, Future.firstCompletedOf)\n  }\n\n  /**\n   * Converts any strict `Future` value into an {@link IO}.\n   *\n   * Note that this builder does not suspend any side effects, since\n   * the given parameter is strict (and not a function) and because\n   * `Future` has strict behavior.\n   *\n   * See {@link IO.deferFuture} for an alternative that evaluates\n   * lazy thunks that produce future results.\n   */\n  static fromFuture<A>(fa: Future<A>): IO<A> {\n    if (!fa.value().isEmpty())\n      return IO.fromTry<A>(fa.value().get() as any)\n\n    return IO.asyncUnsafe<A>((ctx, cb) => {\n      ctx.connection.push(fa)\n      fa.onComplete(result => {\n        ctx.connection.pop()\n        cb(result as any)\n      })\n    })\n  }\n\n  /**\n   * Returns a `IO` reference that will signal the result of the\n   * given `Try<A>` reference upon evaluation.\n   */\n  static fromTry<A>(a: Try<A>): IO<A> { return new IOPure(a) }\n\n  /**\n   * Mirrors the given source `IO`, but before execution trigger\n   * an asynchronous boundary (usually by means of `setTimeout` on\n   * top of JavaScript, depending on the provided `Scheduler`\n   * implementation).\n   *\n   * If a `Scheduler` is not explicitly provided, the implementation\n   * ends up using the one provided in {@link IO.run}.\n   *\n   * Note that {@link IO.executeForked} is the method version of this\n   * function (e.g. `io.executeForked() == IO.fork(this)`).\n   *\n   * ```typescript\n   * IO.of(() => fs.readFileSync(path))\n   *   .executeForked()\n   * ```\n   *\n   * Also see {@link IO.shift} and {@link IO.asyncBoundary}.\n   *\n   * @param fa is the task that will get executed asynchronously\n   *\n   * @param ec is the `Scheduler` used for triggering the async\n   *        boundary, or if not provided it will default to the\n   *        scheduler passed on evaluation in {@link IO.run}\n   */\n  static fork<A>(fa: IO<A>, ec?: Scheduler): IO<A> {\n    return IO.shift(ec).flatMap(() => fa)\n  }\n\n  /**\n   * Maps 2 `IO` values by the mapping function, returning a new\n   * `IO` reference that completes with the result of mapping that\n   * function to the successful values of the futures, or in failure in\n   * case either of them fails.\n   *\n   * This is a specialized {@link IO.sequence} operation and as such\n   * on cancellation or failure all pending tasks get cancelled.\n   *\n   * ```typescript\n   * const fa1 = IO.of(() => 1)\n   * const fa2 = IO.of(() => 2)\n   *\n   *\n   * // Yields Success(3)\n   * IO.map2(fa1, fa2, (a, b) => a + b)\n   *\n   * // Yields Failure, because the second arg is a Failure\n   * IO.map2(fa1, IO.raise(\"error\"),\n   *   (a, b) => a + b\n   * )\n   * ```\n   *\n   * This operation is the `Applicative.map2`.\n   */\n  static map2<A1, A2, R>(\n    fa1: IO<A1>, fa2: IO<A2>,\n    f: (a1: A1, a2: A2) => R): IO<R> {\n\n    const fl: IO<any[]> = IO.sequence([fa1, fa2] as any[])\n    return fl.map(lst => f(lst[0], lst[1]))\n  }\n\n  /**\n   * Maps 3 `IO` values by the mapping function, returning a new\n   * `IO` reference that completes with the result of mapping that\n   * function to the successful values of the futures, or in failure in\n   * case either of them fails.\n   *\n   * This is a specialized {@link IO.sequence} operation and as such\n   * on cancellation or failure all pending tasks get cancelled.\n   *\n   * ```typescript\n   * const fa1 = IO.of(() => 1)\n   * const fa2 = IO.of(() => 2)\n   * const fa3 = IO.of(() => 3)\n   *\n   *\n   * // Yields Success(6)\n   * IO.map3(fa1, fa2, fa3, (a, b, c) => a + b + c)\n   *\n   * // Yields Failure, because the second arg is a Failure\n   * IO.map3(\n   *   fa1, fa2, IO.raise(\"error\"),\n   *   (a, b, c) => a + b + c\n   * )\n   * ```\n   */\n  static map3<A1, A2, A3, R>(\n    fa1: IO<A1>, fa2: IO<A2>, fa3: IO<A3>,\n    f: (a1: A1, a2: A2, a3: A3) => R): IO<R> {\n\n    const fl: IO<any[]> = IO.sequence([fa1, fa2, fa3] as any[])\n    return fl.map(lst => f(lst[0], lst[1], lst[2]))\n  }\n\n  /**\n   * Maps 4 `IO` values by the mapping function, returning a new\n   * `IO` reference that completes with the result of mapping that\n   * function to the successful values of the futures, or in failure in\n   * case either of them fails.\n   *\n   * This is a specialized {@link IO.sequence} operation and as such\n   * on cancellation or failure all pending tasks get cancelled.\n   *\n   * ```typescript\n   * const fa1 = IO.of(() => 1)\n   * const fa2 = IO.of(() => 2)\n   * const fa3 = IO.of(() => 3)\n   * const fa4 = IO.of(() => 4)\n   *\n   * // Yields Success(10)\n   * IO.map4(fa1, fa2, fa3, fa4, (a, b, c, d) => a + b + c + d)\n   *\n   * // Yields Failure, because the second arg is a Failure\n   * IO.map4(\n   *   fa1, fa2, fa3, IO.raise(\"error\"),\n   *   (a, b, c, d) => a + b + c + d\n   * )\n   * ```\n   */\n  static map4<A1, A2, A3, A4, R>(\n    fa1: IO<A1>, fa2: IO<A2>, fa3: IO<A3>, fa4: IO<A4>,\n    f: (a1: A1, a2: A2, a3: A3, a4: A4) => R): IO<R> {\n\n    const fl: IO<any[]> = IO.sequence([fa1, fa2, fa3, fa4] as any[])\n    return fl.map(lst => f(lst[0], lst[1], lst[2], lst[3]))\n  }\n\n  /**\n   * Maps 5 `IO` values by the mapping function, returning a new\n   * `IO` reference that completes with the result of mapping that\n   * function to the successful values of the futures, or in failure in\n   * case either of them fails.\n   *\n   * This is a specialized {@link IO.sequence} operation and as such\n   * on cancellation or failure all pending tasks get cancelled.\n   *\n   * ```typescript\n   * const fa1 = IO.of(() => 1)\n   * const fa2 = IO.of(() => 2)\n   * const fa3 = IO.of(() => 3)\n   * const fa4 = IO.of(() => 4)\n   * const fa5 = IO.of(() => 5)\n   *\n   * // Yields Success(15)\n   * IO.map5(fa1, fa2, fa3, fa4, fa5,\n   *   (a, b, c, d, e) => a + b + c + d + e\n   * )\n   *\n   * // Yields Failure, because the second arg is a Failure\n   * IO.map5(\n   *   fa1, fa2, fa3, fa4, IO.raise(\"error\"),\n   *   (a, b, c, d, e) => a + b + c + d + e\n   * )\n   * ```\n   */\n  static map5<A1, A2, A3, A4, A5, R>(\n    fa1: IO<A1>, fa2: IO<A2>, fa3: IO<A3>, fa4: IO<A4>, fa5: IO<A5>,\n    f: (a1: A1, a2: A2, a3: A3, a4: A4, a5: A5) => R): IO<R> {\n\n    const fl: IO<any[]> = IO.sequence([fa1, fa2, fa3, fa4, fa5] as any[])\n    return fl.map(lst => f(lst[0], lst[1], lst[2], lst[3], lst[4]))\n  }\n\n  /**\n   * Maps 6 `IO` values by the mapping function, returning a new\n   * `IO` reference that completes with the result of mapping that\n   * function to the successful values of the futures, or in failure in\n   * case either of them fails.\n   *\n   * This is a specialized {@link IO.sequence} operation and as such\n   * on cancellation or failure all pending tasks get cancelled.\n   *\n   * ```typescript\n   * const fa1 = IO.of(() => 1)\n   * const fa2 = IO.of(() => 2)\n   * const fa3 = IO.of(() => 3)\n   * const fa4 = IO.of(() => 4)\n   * const fa5 = IO.of(() => 5)\n   * const fa6 = IO.of(() => 6)\n   *\n   * // Yields Success(21)\n   * IO.map6(\n   *   fa1, fa2, fa3, fa4, fa5, fa6,\n   *   (a, b, c, d, e, f) => a + b + c + d + e + f\n   * )\n   *\n   * // Yields Failure, because the second arg is a Failure\n   * IO.map6(\n   *   fa1, fa2, fa3, fa4, fa5, IO.raise(\"error\"),\n   *   (a, b, c, d, e, f) => a + b + c + d + e + f\n   * )\n   * ```\n   */\n  static map6<A1, A2, A3, A4, A5, A6, R>(\n    fa1: IO<A1>, fa2: IO<A2>, fa3: IO<A3>, fa4: IO<A4>, fa5: IO<A5>, fa6: IO<A6>,\n    f: (a1: A1, a2: A2, a3: A3, a4: A4, a5: A5, a6: A6) => R): IO<R> {\n\n    const fl: IO<any[]> = IO.sequence([fa1, fa2, fa3, fa4, fa5, fa6] as any[])\n    return fl.map(lst => f(lst[0], lst[1], lst[2], lst[3], lst[4], lst[5]))\n  }\n\n  /**\n   * Returns an `IO` that on execution is always successful,\n   * emitting the given strict value.\n   */\n  static now<A>(value: A): IO<A> { return new IOPure(Success(value)) }\n\n  /**\n   * Alias for {@link IO.always}.\n   */\n  static of<A>(thunk: () => A): IO<A> {\n    return IO.always(thunk)\n  }\n\n  /**\n   * Promote a `thunk` function to a `Coeval` that is memoized on the\n   * first evaluation, the result being then available on subsequent\n   * evaluations.\n   *\n   * Note this is equivalent with:\n   *\n   * ```typescript\n   * IO.always(thunk).memoize()\n   * ```\n   */\n  static once<A>(thunk: () => A): IO<A> {\n    return new IOOnce(thunk, false)\n  }\n\n  /**\n   * Maps 2 `IO` values evaluated nondeterministically, returning a new\n   * `IO` reference that completes with the result of mapping that\n   * function to the successful values of the futures, or in failure in\n   * case either of them fails.\n   *\n   * This is a specialized {@link IO.gather} operation. As such\n   * the `IO` operations are potentially executed in parallel\n   * (if the operations are asynchronous) and on cancellation or\n   * failure all pending tasks get cancelled.\n   *\n   * ```typescript\n   * const fa1 = IO.of(() => 1)\n   * const fa2 = IO.of(() => 2)\n   *\n   *\n   * // Yields Success(3)\n   * IO.parMap2(fa1, fa2, (a, b) => a + b)\n   *\n   * // Yields Failure, because the second arg is a Failure\n   * IO.parMap2(fa1, IO.raise(\"error\"),\n   *   (a, b) => a + b\n   * )\n   * ```\n   */\n  static parMap2<A1, A2, R>(\n    fa1: IO<A1>, fa2: IO<A2>,\n    f: (a1: A1, a2: A2) => R): IO<R> {\n\n    const fl: IO<any[]> = IO.gather([fa1, fa2] as any[])\n    return fl.map(lst => f(lst[0], lst[1]))\n  }\n\n  /**\n   * Maps 3 `IO` values evaluated nondeterministically, returning a new\n   * `IO` reference that completes with the result of mapping that\n   * function to the successful values of the futures, or in failure in\n   * case either of them fails.\n   *\n   * This is a specialized {@link IO.gather} operation. As such\n   * the `IO` operations are potentially executed in parallel\n   * (if the operations are asynchronous) and on cancellation or\n   * failure all pending tasks get cancelled.\n   *\n   * ```typescript\n   * const fa1 = IO.of(() => 1)\n   * const fa2 = IO.of(() => 2)\n   * const fa3 = IO.of(() => 3)\n   *\n   *\n   * // Yields Success(6)\n   * IO.parMap3(fa1, fa2, fa3, (a, b, c) => a + b + c)\n   *\n   * // Yields Failure, because the second arg is a Failure\n   * IO.parMap3(\n   *   fa1, fa2, IO.raise(\"error\"),\n   *   (a, b, c) => a + b + c\n   * )\n   * ```\n   */\n  static parMap3<A1, A2, A3, R>(\n    fa1: IO<A1>, fa2: IO<A2>, fa3: IO<A3>,\n    f: (a1: A1, a2: A2, a3: A3) => R): IO<R> {\n\n    const fl: IO<any[]> = IO.gather([fa1, fa2, fa3] as any[])\n    return fl.map(lst => f(lst[0], lst[1], lst[2]))\n  }\n\n  /**\n   * Maps 4 `IO` values evaluated nondeterministically, returning a new\n   * `IO` reference that completes with the result of mapping that\n   * function to the successful values of the futures, or in failure in\n   * case either of them fails.\n   *\n   * This is a specialized {@link IO.gather} operation. As such\n   * the `IO` operations are potentially executed in parallel\n   * (if the operations are asynchronous) and on cancellation or\n   * failure all pending tasks get cancelled.\n   *\n   * ```typescript\n   * const fa1 = IO.of(() => 1)\n   * const fa2 = IO.of(() => 2)\n   * const fa3 = IO.of(() => 3)\n   * const fa4 = IO.of(() => 4)\n   *\n   * // Yields Success(10)\n   * IO.parMap4(fa1, fa2, fa3, fa4, (a, b, c, d) => a + b + c + d)\n   *\n   * // Yields Failure, because the second arg is a Failure\n   * IO.parMap4(\n   *   fa1, fa2, fa3, IO.raise(\"error\"),\n   *   (a, b, c, d) => a + b + c + d\n   * )\n   * ```\n   */\n  static parMap4<A1, A2, A3, A4, R>(\n    fa1: IO<A1>, fa2: IO<A2>, fa3: IO<A3>, fa4: IO<A4>,\n    f: (a1: A1, a2: A2, a3: A3, a4: A4) => R): IO<R> {\n\n    const fl: IO<any[]> = IO.gather([fa1, fa2, fa3, fa4] as any[])\n    return fl.map(lst => f(lst[0], lst[1], lst[2], lst[3]))\n  }\n\n  /**\n   * Maps 5 `IO` values evaluated nondeterministically, returning a new\n   * `IO` reference that completes with the result of mapping that\n   * function to the successful values of the futures, or in failure in\n   * case either of them fails.\n   *\n   * This is a specialized {@link IO.gather} operation. As such\n   * the `IO` operations are potentially executed in parallel\n   * (if the operations are asynchronous) and on cancellation or\n   * failure all pending tasks get cancelled.\n   *\n   * ```typescript\n   * const fa1 = IO.of(() => 1)\n   * const fa2 = IO.of(() => 2)\n   * const fa3 = IO.of(() => 3)\n   * const fa4 = IO.of(() => 4)\n   * const fa5 = IO.of(() => 5)\n   *\n   * // Yields Success(15)\n   * IO.parMap5(fa1, fa2, fa3, fa4, fa5,\n   *   (a, b, c, d, e) => a + b + c + d + e\n   * )\n   *\n   * // Yields Failure, because the second arg is a Failure\n   * IO.parMap5(\n   *   fa1, fa2, fa3, fa4, IO.raise(\"error\"),\n   *   (a, b, c, d, e) => a + b + c + d + e\n   * )\n   * ```\n   */\n  static parMap5<A1, A2, A3, A4, A5, R>(\n    fa1: IO<A1>, fa2: IO<A2>, fa3: IO<A3>, fa4: IO<A4>, fa5: IO<A5>,\n    f: (a1: A1, a2: A2, a3: A3, a4: A4, a5: A5) => R): IO<R> {\n\n    const fl: IO<any[]> = IO.gather([fa1, fa2, fa3, fa4, fa5] as any[])\n    return fl.map(lst => f(lst[0], lst[1], lst[2], lst[3], lst[4]))\n  }\n\n  /**\n   * Maps 6 `IO` values evaluated nondeterministically, returning a new\n   * `IO` reference that completes with the result of mapping that\n   * function to the successful values of the futures, or in failure in\n   * case either of them fails.\n   *\n   * This is a specialized {@link IO.gather} operation. As such\n   * the `IO` operations are potentially executed in parallel\n   * (if the operations are asynchronous) and on cancellation or\n   * failure all pending tasks get cancelled.\n   *\n   * ```typescript\n   * const fa1 = IO.of(() => 1)\n   * const fa2 = IO.of(() => 2)\n   * const fa3 = IO.of(() => 3)\n   * const fa4 = IO.of(() => 4)\n   * const fa5 = IO.of(() => 5)\n   * const fa6 = IO.of(() => 6)\n   *\n   * // Yields Success(21)\n   * IO.parMap6(\n   *   fa1, fa2, fa3, fa4, fa5, fa6,\n   *   (a, b, c, d, e, f) => a + b + c + d + e + f\n   * )\n   *\n   * // Yields Failure, because the second arg is a Failure\n   * IO.parMap6(\n   *   fa1, fa2, fa3, fa4, fa5, IO.raise(\"error\"),\n   *   (a, b, c, d, e, f) => a + b + c + d + e + f\n   * )\n   * ```\n   */\n  static parMap6<A1, A2, A3, A4, A5, A6, R>(\n    fa1: IO<A1>, fa2: IO<A2>, fa3: IO<A3>, fa4: IO<A4>, fa5: IO<A5>, fa6: IO<A6>,\n    f: (a1: A1, a2: A2, a3: A3, a4: A4, a5: A5, a6: A6) => R): IO<R> {\n\n    const fl: IO<any[]> = IO.gather([fa1, fa2, fa3, fa4, fa5, fa6] as any[])\n    return fl.map(lst => f(lst[0], lst[1], lst[2], lst[3], lst[4], lst[5]))\n  }\n\n  /**\n   * Lifts a value into the `IO` context.\n   *\n   * Alias for {@link IO.now}.\n   */\n  static pure<A>(value: A): IO<A> { return IO.now(value) }\n\n  /**\n   * Returns an `IO` that on execution is always finishing in error\n   * emitting the specified exception.\n   */\n  static raise<A = never>(e: Throwable): IO<A> { return new IOPure(Failure(e)) }\n\n  /**\n   * Transforms a list of `IO` values into an `IO` of a list,\n   * ordering both results and side effects.\n   *\n   * This operation would be the equivalent of `Promise.all` or of\n   * `Future.sequence`, however because of the laziness of `IO`\n   * the given values are processed in order.\n   *\n   * Sequencing means that on evaluation the tasks won't get processed\n   * in parallel. If parallelism is desired, see {@link IO.gather}.\n   *\n   * Sample:\n   *\n   * ```typescript\n   * const io1 = IO.of(() => 1)\n   * const io2 = IO.of(() => 2)\n   * const io3 = IO.of(() => 3)\n   *\n   * // Yields [1, 2, 3]\n   * const all: IO<number[]> = IO.sequence([f1, f2, f3])\n   * ```\n   */\n  static sequence<A>(list: IO<A>[] | Iterable<IO<A>>): IO<A[]> {\n    return ioSequence(list)\n  }\n\n  /**\n   * Nondeterministically gather results from the given collection of\n   * tasks, returning a task that will signal the same type of\n   * collection of results once all tasks are finished.\n   *\n   * This function is the nondeterministic analogue of `sequence`\n   * and should behave identically to `sequence` so long as there is\n   * no interaction between the effects being gathered. However,\n   * unlike `sequence`, which decides on a total order of effects,\n   * the effects in a `gather` are unordered with respect to each\n   * other.\n   *\n   * In other words `gather` can execute `IO` tasks in parallel,\n   * whereas {@link IO.sequence} forces an execution order.\n   *\n   * Although the effects are unordered, the order of results matches\n   * the order of the input sequence.\n   *\n   * ```typescript\n   * const io1 = IO.of(() => 1)\n   * const io2 = IO.of(() => 2)\n   * const io3 = IO.of(() => 3)\n   *\n   * // Yields [1, 2, 3]\n   * const all: IO<number[]> = IO.gather([f1, f2, f3])\n   * ```\n   */\n  static gather<A>(list: IO<A>[] | Iterable<IO<A>>): IO<A[]> {\n    return ioListToFutureProcess(list, Future.sequence)\n  }\n\n  /**\n   * Shifts the bind continuation of the `IO` onto the specified\n   * scheduler, for triggering asynchronous execution.\n   *\n   * Asynchronous actions cannot be shifted, since they are scheduled\n   * rather than run. Also, no effort is made to re-shift synchronous\n   * actions which *follow* asynchronous actions within a bind chain;\n   * those actions will remain on the continuation call stack inherited\n   * from their preceding async action.  The only computations which\n   * are shifted are those which are defined as synchronous actions and\n   * are contiguous in the bind chain *following* the `shift`.\n   *\n   * For example this sample forces an asynchronous boundary\n   * (which usually means that the continuation is scheduled\n   * for asynchronous execution with `setTimeout`) before the\n   * file will be read synchronously:\n   *\n   * ```typescript\n   * IO.shift().flatMap(_ => fs.readFileSync(path))\n   * ```\n   *\n   * On the other hand in this example the asynchronous boundary\n   * is inserted *after* the file has been read:\n   *\n   * ```typescript\n   * IO.of(() => fs.readFileSync(path)).flatMap(content =>\n   *   IO.shift().map(_ => content))\n   * ```\n   *\n   * The definition of {@link IO.async} is literally:\n   *\n   * ```typescript\n   * source.flatMap(a => IO.shift(ec).map(_ => a))\n   * ```\n   *\n   * And the definition of {@link IO.fork} is:\n   *\n   * ```typescript\n   * IO.shift(ec).flatMap(_ => source)\n   * ```\n   *\n   * @param ec is the `Scheduler` used for triggering the async\n   *        boundary, or if not provided it will default to the\n   *        scheduler passed on evaluation in {@link IO.run}\n   */\n  static shift(ec?: Scheduler): IO<void> {\n    if (!ec) return ioShiftDefaultRef\n    return ioShift(ec)\n  }\n\n  /**\n   * Promote a `thunk` function generating `IO` results to an `IO`\n   * of the same type.\n   */\n  static suspend<A>(thunk: () => IO<A>): IO<A> {\n    return IO.unit().flatMap(() => thunk())\n  }\n\n  /**\n   * Keeps calling `f` until a `Right(b)` is returned.\n   *\n   * Based on Phil Freeman's\n   * [Stack Safety for Free]{@link http://functorial.com/stack-safety-for-free/index.pdf}.\n   *\n   * Described in `FlatMap.tailRecM`.\n   */\n  static tailRecM<A, B>(a: A, f: (a: A) => IO<Either<A, B>>): IO<B> {\n    try {\n      return f(a).flatMap(either => {\n        if (either.isRight()) {\n          return IO.now(either.get())\n        } else {\n          // Recursive call\n          return IO.tailRecM(either.swap().get(), f)\n        }\n      })\n    } catch (e) {\n      return IO.raise(e)\n    }\n  }\n\n  /**\n   * Shorthand for `now(undefined as void)`, always returning\n   * the same reference as optimization.\n   */\n  static unit(): IO<void> {\n    return ioUnitRef\n  }\n\n  /**\n   * Unsafe utility - starts the execution of an `IO`.\n   *\n   * This function allows for specifying a custom {@link IOContext}\n   * when evaluating the `IO` reference.\n   *\n   * DO NOT use directly, as it is UNSAFE to use, unless you know\n   * what you're doing. Prefer {@link IO.run} instead.\n   */\n  static unsafeStart<A>(source: IO<A>, context: IOContext, cb: (r: Try<A>) => void): void | ICancelable {\n    return ioGenericRunLoop(source, context.scheduler, context, cb, null, null, null)\n  }\n}\n\n/**\n * `Pure` is an internal `IO` state that wraps any strict\n * value in an `IO` reference. Returned by {@link IO.now}\n * and {@link IO.raise}.\n *\n * @private\n */\nclass IOPure<A> extends IO<A> {\n  readonly _tag: \"pure\" = \"pure\"\n\n  /**\n   * @param value is the value that's going to be returned\n   * when `get()` is called.\n   */\n  constructor(public value: Try<A>) { super() }\n}\n\n/**\n * Reusable reference, to use in {@link IO.unit}.\n *\n * @private\n */\nconst ioUnitRef: IOPure<void> = new IOPure(Try.unit())\n\n/**\n * `Once` is an internal `IO` state that executes the given `thunk`\n * only once, upon calling `get()` and then memoize its result for\n * subsequent invocations.\n *\n * Returned by [[IO.once]].\n *\n * @private\n */\nclass IOOnce<A> extends IO<A> {\n  readonly _tag: \"once\" = \"once\"\n\n  private _thunk: () => A\n  public cache!: Try<A>\n  public onlyOnSuccess: boolean\n\n  constructor(thunk: () => A, onlyOnSuccess: boolean) {\n    super()\n    this._thunk = thunk\n    this.onlyOnSuccess = onlyOnSuccess\n  }\n\n  memoize(): IO<A> {\n    if (this.onlyOnSuccess && this._thunk)\n      return new IOOnce(this._thunk, false)\n    else\n      return this\n  }\n\n  runTry(): Try<A> {\n    if (this._thunk) {\n      const result = Try.of(this._thunk)\n      if (result.isSuccess() || !this.onlyOnSuccess) {\n        // GC purposes\n        delete this._thunk\n        delete this.onlyOnSuccess\n        this.cache = result\n      }\n      return result\n    }\n    return this.cache\n  }\n}\n\n/**\n * `Always` is an internal `IO` state that executes the given `thunk`\n * every time the call to `get()` happens. Returned by [[IO.always]].\n *\n * @private\n */\nclass IOAlways<A> extends IO<A> {\n  readonly _tag: \"always\" = \"always\"\n\n  constructor(public thunk: () => A) { super() }\n}\n\n/**\n * `FlatMap` is an internal `IO` state that represents a\n * [[IO.flatMap .flatMap]], [[IO.map .map]], [[IO.transform .transform]]\n * or a [[IO.transformWith .transformWith]] operation, all of them\n * being expressed with this state.\n *\n * @private\n */\nclass IOFlatMap<A, B> extends IO<B> {\n  readonly _tag: \"flatMap\" = \"flatMap\"\n\n  constructor(\n    public readonly source: IO<A>,\n    public readonly f: ((a: A) => IO<B>),\n    public readonly g?: ((e: Throwable) => IO<B>)) { super() }\n}\n\n/**\n * Type alias representing registration callbacks for tasks\n * created with `asyncUnsafe`, that are going to get executed\n * when the asynchronous task gets evaluated.\n */\nexport type IORegister<A> =\n  (context: IOContext, callback: (result: Try<A>) => void) => void\n\n/**\n * Constructs a lazy [[IO]] instance whose result will\n * be computed asynchronously.\n *\n * Unsafe to build directly, only use if you know what you're doing.\n * For building `Async` instances safely, see {@link IO.async}.\n *\n * @private\n * @hidden\n */\nclass IOAsync<A> extends IO<A> {\n  readonly _tag: \"async\" = \"async\"\n\n  constructor(public readonly register: IORegister<A>) { super() }\n}\n\nclass IOMemoize<A> extends IO<A> {\n  readonly _tag: \"memoize\" = \"memoize\"\n\n  public result: Try<A> | Future<A> | null\n  public source?: IO<A>\n  public readonly onlySuccess: boolean\n\n  constructor(source: IO<A>, onlySuccess: boolean) {\n    super()\n    this.source = source\n    this.result = null\n    this.onlySuccess = onlySuccess\n  }\n}\n\n/**\n * The `Context` under which {@link IO} is supposed to be executed.\n *\n * This definition is of interest only when creating\n * tasks with {@link IO.asyncUnsafe}, which exposes internals and\n * is considered unsafe to use.\n *\n * @final\n */\nexport class IOContext {\n  /**\n   * The `Scheduler` in charge of evaluating asynchronous boundaries\n   * on `run`.\n   */\n  public readonly scheduler: Scheduler\n\n  /**\n   * Is the `StackedCancelable` that accumulates cancelable\n   * actions, to be triggered if cancellation happens.\n   */\n  public readonly connection: StackedCancelable\n\n  /**\n   * Options passed to the run-loop implementation, determining\n   * its behavior. See {@link IOOptions} for the available\n   * options.\n   */\n  public readonly options: IOOptions\n\n  constructor(\n    scheduler: Scheduler,\n    connection: StackedCancelable = new StackedCancelable(),\n    options: IOOptions = { autoCancelableRunLoops: false }) {\n\n    this.scheduler = scheduler\n    this.options = options\n    this.connection = connection\n\n    // Enables auto-cancelable run-loops\n    if (options.autoCancelableRunLoops)\n      this.shouldCancel = () => connection.isCanceled()\n  }\n\n  /**\n   * Resets the stored `frameIndex`.\n   *\n   * Calling this method inside the logic of a {@link IO.asyncUnsafe}\n   * lets the run-loop know that an async boundary happened. This\n   * works in tandem with the logic for `ExecutionModel.batched(n)`,\n   * for better detection of synchronous cycles, to avoid introducing\n   * forced async boundaries where not needed.\n   */\n  markAsyncBoundary(): void {\n    this.scheduler.batchIndex = 0\n  }\n\n  /**\n   * Returns `true` in case the run-loop should be canceled,\n   * but this can only happen if `autoCancelableRunLoops` is\n   * set to `true`.\n   */\n  shouldCancel(): boolean { return false }\n}\n\n/**\n * Set of options for customizing IO's behavior.\n *\n * @param autoCancelableRunLoops should be set to `true` in\n *        case you want `flatMap` driven loops to be\n *        auto-cancelable. Defaults to `false` because of\n *        safety concerns.\n */\nexport type IOOptions = {\n  autoCancelableRunLoops: boolean\n}\n\n/**\n * Type enumerating the type classes implemented by `Io`.\n */\nexport type IOTypes = Monad<\"funfix/io\">\n\n/**\n * Type-class implementations, compatible with the `static-land`\n * specification.\n */\nexport const IOModule: IOTypes = {\n  // Functor\n  map: <A, B>(f: (a: A) => B, fa: IO<A>) =>\n    fa.map(f),\n  // Apply\n  ap: <A, B>(ff: IO<(a: A) => B>, fa: IO<A>): IO<B> =>\n    fa.ap(ff),\n  // Applicative\n  of: IO.pure,\n  // Chain\n  chain: <A, B>(f: (a: A) => IO<B>, fa: IO<A>): IO<B> =>\n    fa.flatMap(f),\n  // ChainRec\n  chainRec: <A, B>(f: <C>(next: (a: A) => C, done: (b: B) => C, a: A) => IO<C>, a: A): IO<B> =>\n    IO.tailRecM(a, a => f(Either.left as any, Either.right as any, a))\n}\n\n// Registers Fantasy-Land compatible symbols\ncoreInternals.fantasyLandRegister(IO, IOModule)\n\n/** @hidden */\nfunction ioShift(ec?: Scheduler): IO<void> {\n  return IO.asyncUnsafe<void>((ctx, cb) => {\n    (ec || ctx.scheduler).executeAsync(() => cb(Try.unit()))\n  })\n}\n\n/** @hidden */\nconst ioShiftDefaultRef: IO<void> = ioShift()\n\n/** @hidden */\ntype Current = IO<any>\n/** @hidden */\ntype Bind = ((a: any) => IO<any>)\n/** @hidden */\ntype BindT = Bind | [Bind, Bind]\n/** @hidden */\ntype CallStack = Array<BindT>\n\n/** @hidden */\nfunction _ioPopNextBind(bFirst: BindT | null, bRest: CallStack | null): Bind | null {\n  let f: Bind | [Bind, Bind] | null | undefined = undefined\n  if (bFirst) f = bFirst\n  else if (bRest && bRest.length > 0) f = bRest.pop()\n  if (f) return typeof f === \"function\" ? f : f[0]\n  return null\n}\n\n/** @hidden */\nfunction _ioFindErrorHandler(bFirst: BindT | null, bRest: CallStack | null): Bind | null {\n  let cursor: any = bFirst\n  do {\n    if (cursor && typeof cursor !== \"function\") return cursor[1]\n    cursor = bRest ? bRest.pop() : null\n  } while (cursor)\n\n  return null\n}\n\n/**\n * We need to build a callback on each cycle involving an `IOAsync`\n * state. This class builds a mutable callback to reuse on each\n * cycle in order to reduce GC pressure.\n *\n * @hidden\n * @final\n */\nclass RestartCallback {\n  private canCall = false\n  private bFirst: BindT | null = null\n  private bRest: CallStack | null = null\n\n  public readonly asFunction: (result: Try<any>) => void\n\n  constructor(\n    private context: IOContext,\n    private callback: (r: Try<any>) => void) {\n\n    this.asFunction = this.signal.bind(this)\n  }\n\n  prepare(bFirst: BindT | null, bRest: CallStack | null) {\n    this.bFirst = bFirst\n    this.bRest = bRest\n    this.canCall = true\n  }\n\n  signal(result: Try<any>): void {\n    if (this.canCall) {\n      this.canCall = false\n      ioGenericRunLoop(\n        new IOPure(result),\n        this.context.scheduler,\n        this.context,\n        this.callback,\n        this,\n        this.bFirst,\n        this.bRest\n      )\n    } else if (result.isFailure()) {\n      this.context.scheduler.reportFailure(result.failed().get())\n    }\n  }\n}\n\n/** @hidden */\nfunction ioExecuteAsync(\n  register: IORegister<any>,\n  context: IOContext,\n  cb: (result: Try<any>) => void,\n  rcb: RestartCallback | null,\n  bFirst: BindT | null,\n  bRest: CallStack | null,\n  frameIndex: number) {\n\n  if (!context.shouldCancel()) {\n    context.scheduler.batchIndex = frameIndex\n\n    const restart = rcb || new RestartCallback(context, cb)\n    restart.prepare(bFirst, bRest)\n    register(context, restart.asFunction)\n  }\n}\n\n/** @hidden */\nfunction ioRestartAsync(\n  start: IO<any>,\n  context: IOContext,\n  cb: (result: Try<any>) => void,\n  rcb: RestartCallback | null,\n  bFirstInit: BindT | null,\n  bRestInit: CallStack | null): void {\n\n  if (!context.shouldCancel())\n    context.scheduler.executeAsync(() => {\n      ioGenericRunLoop(start, context.scheduler, context, cb, rcb, bFirstInit, bRestInit)\n    })\n}\n\n/** @hidden */\nfunction ioGenericRunLoop(\n  start: IO<any>,\n  scheduler: Scheduler,\n  context: IOContext | null,\n  cb: (result: Try<any>) => void,\n  rcb: RestartCallback | null,\n  bFirstInit: BindT | null,\n  bRestInit: CallStack | null): ICancelable | void {\n\n  let current: Current | Try<any> = start\n  let bFirst: BindT | null = bFirstInit\n  let bRest: CallStack | null = bRestInit\n\n  const modulus = scheduler.executionModel.recommendedBatchSize - 1\n  let frameIndex = scheduler.batchIndex\n\n  while (true) {\n    if (current instanceof Try) {\n      if (current.isSuccess()) {\n        const bind = _ioPopNextBind(bFirst, bRest)\n        if (!bind) {\n          scheduler.batchIndex = frameIndex\n          return cb(current)\n        }\n\n        try {\n          current = bind(current.get())\n        } catch (e) {\n          current = Try.failure(e)\n        }\n      } else {\n        const bind = _ioFindErrorHandler(bFirst, bRest)\n        if (!bind) {\n          scheduler.batchIndex = frameIndex\n          return cb(current)\n        }\n\n        try {\n          current = bind((current as Try<never>).failed().get())\n        } catch (e) {\n          current = Try.failure(e)\n        }\n      }\n\n      bFirst = null\n      const nextIndex = (frameIndex + 1) & modulus\n      // Should we force an asynchronous boundary?\n      if (nextIndex) {\n        frameIndex = nextIndex\n      } else {\n        const ctx = context || new IOContext(scheduler)\n        /* istanbul ignore next */\n        const boxed = current instanceof Try ? new IOPure(current) : current\n        ioRestartAsync(boxed, ctx, cb, rcb, bFirst, bRest)\n        return ctx.connection\n      }\n    }\n    else switch (current._tag) {\n      case \"pure\":\n        current = (current as IOPure<any>).value\n        break\n\n      case \"always\":\n        current = Try.of((current as IOAlways<any>).thunk)\n        break\n\n      case \"once\":\n        current = (current as IOOnce<any>).runTry()\n        break\n\n      case \"flatMap\":\n        const flatM: IOFlatMap<any, any> = current as any\n        if (bFirst) {\n          if (!bRest) bRest = []\n          bRest.push(bFirst)\n        }\n\n        bFirst = !flatM.g ? flatM.f : [flatM.f, flatM.g]\n        current = flatM.source\n        break\n\n      case \"async\":\n        const async: IOAsync<any> = current as any\n        const ctx = context || new IOContext(scheduler)\n        ioExecuteAsync(async.register, ctx, cb, rcb, bFirst, bRest, frameIndex)\n        return ctx.connection\n\n      case \"memoize\":\n        const mem: IOMemoize<any> = current as any\n        return ioStartMemoize(mem, scheduler, context, cb, bFirst, bRest, frameIndex)\n    }\n  }\n}\n\n/** @hidden */\nfunction ioToFutureGoAsync(\n  start: IO<any>,\n  scheduler: Scheduler,\n  bFirst: BindT | null,\n  bRest: CallStack | null,\n  forcedAsync: boolean): Future<any> {\n\n  return Future.create<any>(cb => {\n    const ctx = new IOContext(scheduler)\n    if (forcedAsync)\n      ioRestartAsync(start as any, ctx, cb as any, null, bFirst, bRest)\n    else\n      ioGenericRunLoop(start as any, scheduler, ctx, cb as any, null, bFirst, bRest)\n\n    return ctx.connection\n  })\n}\n\n/** @hidden */\nfunction taskToFutureRunLoop(\n  start: IO<any>,\n  scheduler: Scheduler): Future<any> {\n\n  let current: Current | Try<any> = start\n  let bFirst: BindT | null = null\n  let bRest: CallStack | null = null\n\n  const modulus = scheduler.executionModel.recommendedBatchSize - 1\n  let frameIndex = scheduler.batchIndex\n\n  while (true) {\n    if (current instanceof Try) {\n      if (current.isSuccess()) {\n        const bind = _ioPopNextBind(bFirst, bRest)\n        if (!bind) {\n          scheduler.batchIndex = frameIndex\n          return Future.pure(current.get())\n        }\n\n        try {\n          current = bind(current.get())\n        } catch (e) {\n          current = new IOPure(Try.failure(e))\n        }\n      } else {\n        const err = (current as Try<never>).failed().get()\n        const bind = _ioFindErrorHandler(bFirst, bRest)\n        if (!bind) {\n          scheduler.batchIndex = frameIndex\n          return Future.raise(err)\n        }\n\n        try {\n          current = bind(err)\n        } catch (e) {\n          current = new IOPure(Try.failure(e))\n        }\n      }\n\n      bFirst = null\n      const nextIndex = (frameIndex + 1) & modulus\n      // Should we force an asynchronous boundary?\n      if (nextIndex) {\n        frameIndex = nextIndex\n      } else {\n        return ioToFutureGoAsync(current, scheduler, bFirst, bRest, true)\n      }\n    }\n    else switch (current._tag) {\n      case \"pure\":\n        current = (current as IOPure<any>).value\n        break\n\n      case \"always\":\n        current = Try.of((current as IOAlways<any>).thunk)\n        break\n\n      case \"once\":\n        current = (current as IOOnce<any>).runTry()\n        break\n\n      case \"flatMap\":\n        const flatM: IOFlatMap<any, any> = current as any\n        if (bFirst) {\n          if (!bRest) bRest = []\n          bRest.push(bFirst)\n        }\n\n        bFirst = !flatM.g ? flatM.f : [flatM.f, flatM.g]\n        current = flatM.source\n        break\n\n      case \"async\":\n      case \"memoize\":\n        return ioToFutureGoAsync(current, scheduler, bFirst, bRest, false)\n    }\n  }\n}\n\n/**\n * Internal utility used in the implementation of `IO.async`.\n *\n * @hidden\n */\nfunction ioSafeCallback<A>(\n  ec: Scheduler,\n  conn: StackedCancelable,\n  cb: (r: Try<A>) => void): ((r: Try<A>) => void) {\n\n  let called = false\n  return (r: Try<A>) => {\n    if (!called) {\n      called = true\n      // Inserting a light async boundary, otherwise we can have\n      // stack overflow issues, but also ordering issues with\n      // StackedCancelable.push in IO.async!\n      ec.trampoline(() => {\n        conn.pop()\n        cb(r)\n      })\n    } else if (r.isFailure()) {\n      ec.reportFailure(r.failed().get())\n    }\n  }\n}\n\n/** @hidden */\nfunction ioStartMemoize<A>(\n  fa: IOMemoize<A>,\n  ec: Scheduler,\n  context: IOContext | null,\n  cb: (r: Try<A>) => void,\n  bFirstInit: BindT | null,\n  bRestInit: CallStack | null,\n  frameIndex: number): ICancelable | void {\n\n  // Storing the current frameIndex because invoking this\n  // function effectively ends the current run-loop\n  ec.batchIndex = frameIndex\n  // The state that we'll use for subscribing listeners below\n  let state: Try<A> | Future<A>\n\n  // The first evaluation has to trigger the initial run-loop that\n  // will eventually set our completed state\n  if (fa.result) {\n    state = fa.result\n  } else {\n    // NOTE this isn't using the passed `IOContext`, or the bindings\n    // stack because it would be wrong. This has to be executed\n    // independently, within its own context.\n    const f = ioToFutureGoAsync(fa.source as any, ec, null, null, false)\n\n    if (f.value().isEmpty()) {\n      fa.result = f\n      state = f\n\n      f.onComplete(r => {\n        if (r.isSuccess() || !fa.onlySuccess) {\n          // Caching result for subsequent listeners\n          fa.result = r as any\n          // GC purposes\n          delete fa.source\n        } else {\n          // Reverting the state to the original IO reference, such\n          // that it can be retried again\n          fa.result = null\n        }\n      })\n    } else {\n      state = (f.value().get() as any) as Try<any>\n      // Not storing the state on memoizeOnSuccess if it's a failure\n      if (state.isSuccess() || !fa.onlySuccess)\n        fa.result = state as any\n    }\n  }\n\n  // We have the IOMemoize in an already completed state,\n  // so running with it\n  const io: IO<A> = state instanceof Try\n    ? new IOPure(state)\n    : IO.fromFuture(state)\n\n  ioGenericRunLoop(io, ec, context, cb, null, bFirstInit, bRestInit)\n}\n\n/**\n * Implementation for `IO.sequence`.\n * @hidden\n */\nfunction ioSequence<A>(list: IO<A>[] | Iterable<IO<A>>): IO<A[]> {\n  return IO.of(() => iteratorOf(list))\n    .flatMap(cursor => ioSequenceLoop([], cursor))\n}\n\n/**\n * Recursive loop that goes through the given `cursor`, element by\n * element, gathering the results of all generated `IO` elements.\n *\n * @hidden\n */\nfunction ioSequenceLoop<A>(acc: A[], cursor: IteratorLike<IO<A>>): IO<A[]> {\n  while (true) {\n    const elem = cursor.next()\n    const isDone = elem.done\n\n    if (elem.value) {\n      const io: IO<A> = elem.value\n      return io.flatMap(a => {\n        acc.push(a)\n        if (isDone) return IO.pure(acc)\n        return ioSequenceLoop(acc, cursor)\n      })\n    } else {\n      /* istanbul ignore else */\n      if (isDone) return IO.pure(acc)\n    }\n  }\n}\n\n/** @hidden */\nfunction ioListToFutureProcess<A, B>(list: IO<A>[] | Iterable<IO<A>>, f: (list: Future<A>[], ec: Scheduler) => Future<B>): IO<B> {\n  return IO.asyncUnsafe<B>((ctx, cb) => {\n    ctx.scheduler.trampoline(() => {\n      let streamErrors = true\n      try {\n        const futures: Future<A>[] = []\n        const array: IO<A>[] = execInternals.iterableToArray(list)\n        streamErrors = false\n\n        for (let i = 0; i < array.length; i++) {\n          const io = array[i]\n          const f = io.run(ctx.scheduler)\n          futures.push(f)\n        }\n\n        const all = f(futures, ctx.scheduler)\n        ctx.connection.push(all)\n        all.onComplete(ioSafeCallback(ctx.scheduler, ctx.connection, cb) as any)\n      } catch (e) {\n        /* istanbul ignore else */\n        if (streamErrors) cb(Failure(e))\n        else ctx.scheduler.reportFailure(e)\n      }\n    })\n  })\n}\n"],"names":["emptyIteratorRef","next","done","list","Object","prototype","toString","call","Symbol","iterator","array","length","cursor","value","evalRunLoop","f","FlatMap","a","Eval","now","flatMap","ff","map","_tag","Once","get","cb","forEachL","thunk","always","Now","evalUnitRef","Always","Suspend","suspend","either","isRight","tailRecM","swap","evalSequence","fa1","fa2","fl","sequence","lst","fa3","fa4","fa5","fa6","JSON","stringify","undefined","_thunk","_cache","_isError","e","source","String","EvalModule","fa","ap","pure","Either","left","right","coreInternals","fantasyLandRegister","bFirst","bRest","pop","start","current","bind","_popNextBind","push","fm","of","iteratorOf","evalSequenceLoop","acc","elem","isDone","io","ec","Scheduler","global","taskToFutureRunLoop","ref","ioGenericRunLoop","Cancelable","empty","transform","_","IO","shift","delay","delayedTick","transformWith","raise","err","Some","None","callback","asyncUnsafe","ctx","scheduler","trampoline","conn","connection","run","unsafeStart","ioSafeCallback","fork","em","withExecutionModel","ctx2","IOContext","options","set","IOFlatMap","fb","IOOnce","mem","onlySuccess","IOMemoize","recoverWith","after","TimeoutError","Duration","timeoutTo","fallback","other","firstCompletedOf","failure","success","IOAlways","register","safe","Failure","IOAsync","unit","ioa","fromFuture","deferAction","task","scheduleOnce","Try","ioListToFutureProcess","Future","isEmpty","fromTry","onComplete","result","IOPure","Success","gather","ioSequence","ioShiftDefaultRef","ioShift","ioUnitRef","context","onlyOnSuccess","isSuccess","cache","g","StackedCancelable","autoCancelableRunLoops","shouldCancel","isCanceled","batchIndex","IOModule","executeAsync","asFunction","signal","canCall","isFailure","reportFailure","failed","rcb","frameIndex","restart","RestartCallback","prepare","bFirstInit","bRestInit","modulus","executionModel","recommendedBatchSize","_ioPopNextBind","_ioFindErrorHandler","nextIndex","boxed","runTry","flatM","async","ioStartMemoize","forcedAsync","create","ioRestartAsync","ioToFutureGoAsync","called","r","state","ioSequenceLoop","streamErrors","futures","execInternals","iterableToArray","i","all"],"mappings":";;;;;;AAgCO,IAAMA,mBACX,EAAEC,MAAM;eAAO,EAAEC,MAAM,IAAR,EAAP;KAAR,EADK;;AASP,oBAA8BC;QACxB,CAACA,IAAL,EAAW,OAAOH,gBAAP;QACPI,OAAOC,SAAP,CAAiBC,QAAjB,CAA0BC,IAA1B,CAA+BJ,IAA/B,MAAyC,gBAA7C,EACE,OAAOA,KAAKK,OAAOC,QAAZ,GAAP;QAEIC,QAAQP,IAAd;QACIO,MAAMC,MAAN,KAAiB,CAArB,EAAwB,OAAOX,gBAAP;QAEpBY,SAAS,CAAb;QACMX,OAAO,SAAPA,IAAO;YACLY,QAAQH,MAAME,QAAN,CAAd;YACMV,OAAOU,UAAUF,MAAMC,MAA7B;eACO,EAAET,UAAF,EAAQW,YAAR,EAAP;KAHF;WAMO,EAAEZ,UAAF,EAAP;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;QC4CF;;;;;;;;mBAUoBa,YAAY,IAAZ,CAAP;;;;4BAUJC,CApBT;mBAqBW,IAAIC,OAAJ,CAAY,IAAZ,EAAkB,UAACC,CAAD;uBAAUC,KAAKC,GAAL,CAASJ,EAAEE,CAAF,CAAT,CAAV;aAAlB,CAAP;;;;gCAuBSF,CA5Cb;mBA6CW,IAAIC,OAAJ,CAAY,IAAZ,EAAkBD,CAAlB,CAAP;;;;8BAIOA,CAjDX;mBAkDW,KAAKK,OAAL,CAAaL,CAAb,CAAP;;;;2BASIM,EA3DR;;;mBA4DWA,GAAGD,OAAH,CAAW;uBAAK,MAAKE,GAAL,CAASP,CAAT,CAAL;aAAX,CAAP;;;;;;;oBAYQ,KAAKQ,IAAb;qBACO,KAAL;qBACK,MAAL;2BACS,IAAP;qBACG,QAAL;2BACS,IAAIC,IAAJ,CAAS,KAAKC,GAAd,CAAP;;2BAEO,IAAID,IAAJ,CAAS;+BAAM,OAAKC,GAAL,EAAN;qBAAT,CAAP;;;;;iCAYGC,EA3FX;mBA4FW,KAAKJ,GAAL,CAASI,EAAT,CAAP;;;;gCAUMA,EAtGV;iBAuGSC,QAAL,CAAcD,EAAd,EAAkBD,GAAlB;;;;2BAoBWG,KA3Hf;mBA4HWV,KAAKW,MAAL,CAAYD,KAAZ,CAAP;;;;6BAQaf,KApIjB;mBAoI6CK,KAAKC,GAAL,CAASN,KAAT,CAAP;;;;4BAMtBA,KA1IhB;mBA0I4C,IAAIiB,GAAJ,CAAQjB,KAAR,CAAP;;;;;mBAO1BkB,WAAP;;;;+BAUeH,KA3JnB;mBA4JW,IAAII,MAAJ,CAAWJ,KAAX,CAAP;;;;6BAcaA,KA1KjB;mBA2KW,IAAIJ,IAAJ,CAASI,KAAT,CAAP;;;;gCAOgBA,KAlLpB;mBAmLW,IAAIK,OAAJ,CAAYL,KAAZ,CAAP;;;;8BAScA,KA5LlB;mBA6LWV,KAAKgB,OAAL,CAAaN,KAAb,CAAP;;;;iCAWoBX,CAxMxB,EAwM8BF,CAxM9B;mBAyMWA,EAAEE,CAAF,EAAKG,OAAL,CAAa;oBACde,OAAOC,OAAP,EAAJ,EAAsB;2BACblB,KAAKC,GAAL,CAASgB,OAAOV,GAAP,EAAT,CAAP;iBADF,MAEO;2BAEEP,KAAKmB,QAAL,CAAcF,OAAOG,IAAP,GAAcb,GAAd,EAAd,EAAmCV,CAAnC,CAAP;;aALG,CAAP;;;;iCAwBiBZ,IAjOrB;mBAkOWoC,aAAapC,IAAb,CAAP;;;;6BAqBAqC,GAvPJ,EAuPmBC,GAvPnB,EAwPI1B,CAxPJ;gBA0PU2B,KAAkBxB,KAAKyB,QAAL,CAAc,CAACH,GAAD,EAAMC,GAAN,CAAd,CAAxB;mBACOC,GAAGpB,GAAH,CAAO;uBAAOP,EAAE6B,IAAI,CAAJ,CAAF,EAAUA,IAAI,CAAJ,CAAV,CAAP;aAAP,CAAP;;;;6BAoBAJ,GA/QJ,EA+QmBC,GA/QnB,EA+QkCI,GA/QlC,EAgRI9B,CAhRJ;gBAkRU2B,KAAkBxB,KAAKyB,QAAL,CAAc,CAACH,GAAD,EAAMC,GAAN,EAAWI,GAAX,CAAd,CAAxB;mBACOH,GAAGpB,GAAH,CAAO;uBAAOP,EAAE6B,IAAI,CAAJ,CAAF,EAAUA,IAAI,CAAJ,CAAV,EAAkBA,IAAI,CAAJ,CAAlB,CAAP;aAAP,CAAP;;;;6BAoBAJ,GAvSJ,EAuSmBC,GAvSnB,EAuSkCI,GAvSlC,EAuSiDC,GAvSjD,EAwSI/B,CAxSJ;gBA0SU2B,KAAkBxB,KAAKyB,QAAL,CAAc,CAACH,GAAD,EAAMC,GAAN,EAAWI,GAAX,EAAgBC,GAAhB,CAAd,CAAxB;mBACOJ,GAAGpB,GAAH,CAAO;uBAAOP,EAAE6B,IAAI,CAAJ,CAAF,EAAUA,IAAI,CAAJ,CAAV,EAAkBA,IAAI,CAAJ,CAAlB,EAA0BA,IAAI,CAAJ,CAA1B,CAAP;aAAP,CAAP;;;;6BAuBAJ,GAlUJ,EAkUmBC,GAlUnB,EAkUkCI,GAlUlC,EAkUiDC,GAlUjD,EAkUgEC,GAlUhE,EAmUIhC,CAnUJ;gBAqUU2B,KAAkBxB,KAAKyB,QAAL,CAAc,CAACH,GAAD,EAAMC,GAAN,EAAWI,GAAX,EAAgBC,GAAhB,EAAqBC,GAArB,CAAd,CAAxB;mBACOL,GAAGpB,GAAH,CAAO;uBAAOP,EAAE6B,IAAI,CAAJ,CAAF,EAAUA,IAAI,CAAJ,CAAV,EAAkBA,IAAI,CAAJ,CAAlB,EAA0BA,IAAI,CAAJ,CAA1B,EAAkCA,IAAI,CAAJ,CAAlC,CAAP;aAAP,CAAP;;;;6BAyBAJ,GA/VJ,EA+VmBC,GA/VnB,EA+VkCI,GA/VlC,EA+ViDC,GA/VjD,EA+VgEC,GA/VhE,EA+V+EC,GA/V/E,EAgWIjC,CAhWJ;gBAkWU2B,KAAkBxB,KAAKyB,QAAL,CAAc,CAACH,GAAD,EAAMC,GAAN,EAAWI,GAAX,EAAgBC,GAAhB,EAAqBC,GAArB,EAA0BC,GAA1B,CAAd,CAAxB;mBACON,GAAGpB,GAAH,CAAO;uBAAOP,EAAE6B,IAAI,CAAJ,CAAF,EAAUA,IAAI,CAAJ,CAAV,EAAkBA,IAAI,CAAJ,CAAlB,EAA0BA,IAAI,CAAJ,CAA1B,EAAkCA,IAAI,CAAJ,CAAlC,EAA0CA,IAAI,CAAJ,CAA1C,CAAP;aAAP,CAAP;;;;;;;;;iBAiB0B/B,KAA5B;;;;;oBAA4B,GAAAA,KAAA;mBANnB,GAAc,KAAd;;;;;;;mBAQS,KAAKA,KAAZ;;;;;iCAC6BoC,KAAKC,SAAL,CAAe,KAAKrC,KAApB,CAAnB;;;;EAVFK;;AAkBrB,IAAMa,cAAyB,IAAID,GAAJ,CAAQqB,SAAR,CAA/B;;;;;kBAkBcvB,KAAZ;;;;;mBANS,GAAe,MAAf;eAQFwB,MAAL,GAAcxB,KAAd;;;;;;;gBAII,KAAKwB,MAAT,EAAiB;oBACX;yBACGC,MAAL,GAAc,KAAKD,MAAL,EAAd;yBACKE,QAAL,GAAgB,KAAhB;iBAFF,CAGE,OAAOC,CAAP,EAAU;yBACLF,MAAL,GAAcE,CAAd;yBACKD,QAAL,GAAgB,IAAhB;;;uBAGK,KAAKF,MAAZ;;gBAGE,KAAKE,QAAT,EAAmB,MAAM,KAAKD,MAAX;mBACZ,KAAKA,MAAZ;;;;;;;;;EA1BkBnC;;;;;oBAyCRU,KAAZ;;;;;mBAFS,GAAiB,QAAjB;eAIFH,GAAL,GAAWG,KAAX;;;;;;;;;;;EALoBV;;;;;qBAoBMU,KAA5B;;;;;oBAA4B,GAAAA,KAAA;mBAFnB,GAAkB,SAAlB;;;;;;;;;;;EADcV;;;;;qBAkBLsC,MADlB,EAEkBzC,CAFlB;;;;;qBACkB,GAAAyC,MAAA;gBACA,GAAAzC,CAAA;mBAJT,GAAkB,SAAlB;;;;;;;qCAOgB0C,OAAO,KAAKD,MAAZ,CAAvB;;;;EARwBtC;;AAqB5B,IAAawC,aAAwB;SAE9B,aAAO3C,CAAP,EAAuB4C,EAAvB;eACHA,GAAGrC,GAAH,CAAOP,CAAP,CADG;KAF8B;;QAK/B,YAAOM,EAAP,EAA8BsC,EAA9B;eACFA,GAAGC,EAAH,CAAMvC,EAAN,CADE;KAL+B;;QAQ/BH,KAAK2C,IAR0B;;WAU5B,eAAO9C,CAAP,EAA6B4C,EAA7B;eACLA,GAAGvC,OAAH,CAAWL,CAAX,CADK;KAV4B;;cAazB,kBAAOA,CAAP,EAAsEE,CAAtE;eACRC,KAAKmB,QAAL,CAAcpB,CAAd,EAAiB;mBAAKF,EAAE+C,kBAAOC,IAAT,EAAsBD,kBAAOE,KAA7B,EAA2C/C,CAA3C,CAAL;SAAjB,CADQ;;CAbL;;AAkBPgD,yBAAcC,mBAAd,CAAkChD,IAAlC,EAAwCwC,UAAxC;;AAUA,qBAAA,CAAsBS,MAAtB,EAA2CC,KAA3C;QACMD,MAAJ,EAAY,OAAOA,MAAP;QACRC,SAASA,MAAMzD,MAAN,GAAe,CAA5B,EAA+B,OAAOyD,MAAMC,GAAN,EAAP;WACxB,IAAP;;;AAIF,oBAAA,CAAwBC,KAAxB;QACMC,UAAmBD,KAAvB;QACIH,SAAsB,IAA1B;QACIC,QAA0B,IAA9B;WAEO,IAAP,EAAa;gBACHG,QAAQhD,IAAhB;iBACO,KAAL;oBACQJ,MAAMoD,OAAZ;oBACMC,OAAOC,aAAaN,MAAb,EAAqBC,KAArB,CAAb;oBACI,CAACI,IAAL,EAAW,OAAOrD,IAAIN,KAAX;yBACF,IAAT;0BACU2D,KAAKrD,IAAIN,KAAT,CAAV;;iBAGG,QAAL;iBACK,MAAL;0BACY,IAAIiB,GAAJ,CAAQyC,QAAQ9C,GAAR,EAAR,CAAV;;iBAGG,SAAL;0BACa8C,QAAuB3C,KAAvB,EAAX;;iBAGG,SAAL;oBACMuC,MAAJ,EAAY;wBACN,CAACC,KAAL,EAAYA,QAAQ,EAAR;0BACNM,IAAN,CAAWP,MAAX;;oBAEIQ,KAAKJ,OAAX;yBACSI,GAAG5D,CAAZ;0BACU4D,GAAGnB,MAAb;;;;;;AAUR,qBAAA,CAAyBrD,IAAzB;WACSe,KAAK0D,EAAL,CAAQ;eAAMC,WAAW1E,IAAX,CAAN;KAAR,EACJiB,OADI,CACI;eAAU0D,iBAAiB,EAAjB,EAAqBlE,MAArB,CAAV;KADJ,CAAP;;;AAUF,yBAAA,CAA6BmE,GAA7B,EAAuCnE,MAAvC;;YAEUoE,OAAOpE,OAAOX,IAAP,EAAb;YACMgF,SAASD,KAAK9E,IAApB;YAEI8E,KAAKnE,KAAT,EAAgB;gBACRqE,KAAcF,KAAKnE,KAAzB;;mBACOqE,GAAG9D,OAAH,CAAW;wBACZsD,IAAJ,CAASzD,CAAT;wBACIgE,MAAJ,EAAY,OAAO/D,KAAK2C,IAAL,CAAUkB,GAAV,CAAP;2BACLD,iBAAiBC,GAAjB,EAAsBnE,MAAtB,CAAP;iBAHK;;SAFT,MAOO;gBAEDqE,MAAJ,EAAY;uBAAO/D,KAAK2C,IAAL,CAAUkB,GAAV;;;;;WAbhB,IAAP,EAAa;;;;;;;MC7Tf;;;;;;;;gBAoCMI,yEAAgBC,qBAAUC,MAAV,CAAiB5D,GAAjB;;mBACX6D,oBAAoB,IAApB,EAA0BH,EAA1B,CAAP;;;;sCAsEAzD,EA3GJ;gBA4GIyD,yEAAgBC,qBAAUC,MAAV,CAAiB5D,GAAjB;;gBAEV8D,MAAMC,iBAAiB,IAAjB,EAAuBL,EAAvB,EAA2B,IAA3B,EAAiCzD,EAAjC,EAAqC,IAArC,EAA2C,IAA3C,EAAiD,IAAjD,CAAZ;mBACO6D,OAAOE,sBAAWC,KAAX,EAAd;;;;;mBAqCO,KAAKC,SAAL,CACL;uBAAK7B,kBAAOC,IAAP,CAA0B6B,CAA1B,CAAL;aADK,EAEL9B,kBAAOE,KAFF,CAAP;;;;sCAyCYmB,EA7LhB;mBA8LW,KAAK/D,OAAL,CAAa;uBAAKyE,GAAGC,KAAH,CAASX,EAAT,EAAa7D,GAAb,CAAiB;2BAAML,CAAN;iBAAjB,CAAL;aAAb,CAAP;;;;8BAMOF,CApMX;mBAqMW,KAAKK,OAAL,CAAaL,CAAb,CAAP;;;;uCAgBagF,KArNjB;;;mBAsNWF,GAAGG,WAAH,CAAeD,KAAf,EAAsB3E,OAAtB,CAA8B;;aAA9B,CAAP;;;;oCAyBU2E,KA/Od;mBAgPW,KAAKE,aAAL,CACL;uBAAOJ,GAAGG,WAAH,CAAeD,KAAf,EAAsB3E,OAAtB,CAA8B;2BAAMyE,GAAGK,KAAH,CAASC,GAAT,CAAN;iBAA9B,CAAP;aADK,EAEL;uBAAKN,GAAGG,WAAH,CAAeD,KAAf,EAAsBzE,GAAtB,CAA0B;2BAAML,CAAN;iBAA1B,CAAL;aAFK,CAAP;;;;mCAsBSF,CAtQb;mBAuQW,KAAKkF,aAAL,CACL;uBAAKlF,EAAEqF,gBAAK7C,CAAL,CAAF,EAAWnC,OAAX,CAAmB;2BAAMyE,GAAGK,KAAH,CAAS3C,CAAT,CAAN;iBAAnB,CAAL;aADK,EAEL;uBAAKxC,EAAEsF,eAAF,EAAQ/E,GAAR,CAAY;2BAAML,CAAN;iBAAZ,CAAL;aAFK,CAAP;;;;mCAkBSqF,QAzRb;;;mBA0RWT,GAAGU,WAAH,CAAkB,UAACC,GAAD,EAAM9E,EAAN;oBACjByD,KAAKqB,IAAIC,SAAf;mBACGC,UAAH,CAAc;wBACNC,OAAOH,IAAII,UAAjB;yBACKlC,IAAL,CAAUe,sBAAWb,EAAX,CAAc;+BAAM0B,SAASO,GAAT,CAAa1B,EAAb,CAAN;qBAAd,CAAV;uBACG2B,WAAH,SAAqBN,GAArB,EAA0BO,eAAe5B,EAAf,EAAmBwB,IAAnB,EAAyBjF,EAAzB,CAA1B;iBAHF;aAFK,CAAP;;;;sCA4BYyD,EAtThB;mBAuTWU,GAAGmB,IAAH,CAAQ,IAAR,EAAc7B,EAAd,CAAP;;;;yCAYe8B,EAnUnB;;;mBAoUWpB,GAAGU,WAAH,CAAkB,UAACC,GAAD,EAAM9E,EAAN;oBACjByD,KAAKqB,IAAIC,SAAJ,CAAcS,kBAAd,CAAiCD,EAAjC,CAAX;oBACME,OAAO,IAAIC,SAAJ,CAAcjC,EAAd,EAAkBqB,IAAII,UAAtB,EAAkCJ,IAAIa,OAAtC,CAAb;mBACGX,UAAH,CAAc;2BAAMb,GAAGiB,WAAH,SAAqBK,IAArB,EAA2BzF,EAA3B,CAAN;iBAAd;aAHK,CAAP;;;;2CAoBiB4F,MAxVrB;;;mBAyVWzB,GAAGU,WAAH,CAAkB,UAACC,GAAD,EAAM9E,EAAN;oBACjByD,KAAKqB,IAAIC,SAAf;oBACMU,OAAO,IAAIC,SAAJ,CAAcjC,EAAd,EAAkBqB,IAAII,UAAtB,EAAkCU,MAAlC,CAAb;mBACGZ,UAAH,CAAc;2BAAMb,GAAGiB,WAAH,SAAqBK,IAArB,EAA2BzF,EAA3B,CAAN;iBAAd;aAHK,CAAP;;;;gCA2BSX,CApXb;mBAqXW,IAAIwG,SAAJ,CAAc,IAAd,EAAoBxG,CAApB,CAAP;;;;2BASIM,EA9XR;;;mBA+XWA,GAAGD,OAAH,CAAW;uBAAK,OAAKE,GAAL,CAASP,CAAT,CAAL;aAAX,CAAP;;;;mCAmBYyG,EAlZhB;mBAmZW,KAAKpG,OAAL,CAAa;uBAAMoG,EAAN;aAAb,CAAP;;;;gCAQM9F,EA3ZV;mBA4ZW,KAAKJ,GAAL,CAASI,EAAT,CAAP;;;;kCAmBW8F,EA/af;mBAgbW,KAAKpG,OAAL,CAAa;uBAAKoG,GAAGlG,GAAH,CAAO;2BAAML,CAAN;iBAAP,CAAL;aAAb,CAAP;;;;4BAiBKF,CAjcT;mBAkcW,IAAIwG,SAAJ,CAAc,IAAd,EAAoB,UAACtG,CAAD;uBAAU4E,GAAG1E,GAAH,CAAOJ,EAAEE,CAAF,CAAP,CAAV;aAApB,CAAP;;;;;oBAeQ,KAAKM,IAAb;qBACO,MAAL;2BACS,IAAP;qBACG,QAAL;wBACQM,SAAU,IAAhB;2BACO,IAAI4F,MAAJ,CAAW5F,OAAOD,KAAlB,EAAyB,KAAzB,CAAP;qBACG,SAAL;wBACQ8F,MAAO,IAAb;wBACI,CAACA,IAAIC,WAAT,EAAsB,OAAOD,GAAP;2BACf,IAAIE,SAAJ,CAAc,IAAd,EAAoB,KAApB,CAAP;;2BAEO,IAAIA,SAAJ,CAAc,IAAd,EAAoB,KAApB,CAAP;;;;;;oBAgBI,KAAKrG,IAAb;qBACO,MAAL;qBACK,MAAL;qBACK,SAAL;2BACS,IAAP;qBACG,QAAL;wBACQM,SAAU,IAAhB;2BACO,IAAI4F,MAAJ,CAAW5F,OAAOD,KAAlB,EAAyB,IAAzB,CAAP;;2BAEO,IAAIgG,SAAJ,CAAc,IAAd,EAAoB,IAApB,CAAP;;;;;gCAmBM7G,CAxgBd;mBAygBW,KAAK8G,WAAL,CAAiB;uBAAKhC,GAAG1E,GAAH,CAAOJ,EAAEE,CAAF,CAAP,CAAL;aAAjB,CAAP;;;;oCA2BcF,CApiBlB;mBAqiBW,KAAKkF,aAAL,CAAmBlF,CAAnB,EAAsB8E,GAAG1E,GAAzB,CAAP;;;;gCAmBM2G,KAxjBV;gBAyjBUN,KAAK3B,GAAGK,KAAH,CAAS,IAAI6B,uBAAJ,CAAiBC,oBAASpD,EAAT,CAAYkD,KAAZ,EAAmBxH,QAAnB,EAAjB,CAAT,CAAX;mBACO,KAAK2H,SAAL,CAAeH,KAAf,EAAsBN,EAAtB,CAAP;;;;kCAqBYM,KA/kBhB,EA+kB0CI,QA/kB1C;gBAglBUC,QAAQtC,GAAGG,WAAH,CAAe8B,KAAf,EAAsB1G,OAAtB,CAA8B;uBAAM8G,QAAN;aAA9B,CAAd;gBACMtF,MAAoB,CAAC,IAAD,EAAOuF,KAAP,CAA1B;mBACOtC,GAAGuC,gBAAH,CAAoBxF,GAApB,CAAP;;;;kCAcWyF,OAhmBf,EAgmB6CC,OAhmB7C;mBAimBW,KAAKrC,aAAL,CACL;uBAAKJ,GAAG1E,GAAH,CAAOkH,QAAQ9E,CAAR,CAAP,CAAL;aADK,EAEL;uBAAKsC,GAAG1E,GAAH,CAAOmH,QAAQrH,CAAR,CAAP,CAAL;aAFK,CAAP;;;;sCAkBeoH,OAnnBnB,EAmnBqDC,OAnnBrD;mBAonBW,IAAIf,SAAJ,CAAc,IAAd,EAAoBe,OAApB,EAA6BD,OAA7B,CAAP;;;;+BAoCezG,KAxpBnB;mBAypBW,IAAI2G,QAAJ,CAAa3G,KAAb,CAAP;;;;8BAUc4G,QAnqBlB;mBAoqBW3C,GAAGU,WAAH,CAAkB,UAACC,GAAD,EAAM9E,EAAN;oBACjByD,KAAKqB,IAAIC,SAAf;oBACME,OAAOH,IAAII,UAAjB;;mBAIGF,UAAH,CAAc;wBAIN+B,OAAO1B,eAAe5B,EAAf,EAAmBwB,IAAnB,EAAyBjF,EAAzB,CAAb;wBACI;4BACI6D,MAAMiD,SAASrD,EAAT,EAAasD,IAAb,CAAZ;;6BAIK/D,IAAL,CAAUa,OAAOE,sBAAWC,KAAX,EAAjB;qBALF,CAME,OAAOnC,CAAP,EAAU;6BACLmF,mBAAQnF,CAAR,CAAL;;iBAZJ;aANK,CAAP;;;;oCAsDoBiF,QA1tBxB;mBA2tBW,IAAIG,OAAJ,CAAYH,QAAZ,CAAP;;;;8BASc5G,KApuBlB;mBAquBWiE,GAAG+C,IAAH,GAAUxH,OAAV,CAAkB;uBAAMQ,OAAN;aAAlB,CAAP;;;;oCA2BoBb,CAhwBxB;mBAiwBW8E,GAAGU,WAAH,CAAkB,UAACC,GAAD,EAAM9E,EAAN;oBACjByD,KAAKqB,IAAIC,SAAf;oBACIoC,YAAJ;oBACI;0BAAQ9H,EAAEoE,EAAF,CAAN;iBAAN,CAAoB,OAAO5B,CAAP,EAAU;0BAAQsC,GAAGK,KAAH,CAAS3C,CAAT,CAAN;;mBAC7BmD,UAAH,CAAc;2BAAMb,GAAGiB,WAAH,CAAe+B,GAAf,EAAoBrC,GAApB,EAAyB9E,EAAzB,CAAN;iBAAd;aAJK,CAAP;;;;oCAeoBE,KAhxBxB;mBAixBWiE,GAAG3D,OAAH,CAAW;uBAAM2D,GAAGiD,UAAH,CAAclH,OAAd,CAAN;aAAX,CAAP;;;;0CAa0Bb,CA9xB9B;mBA+xBW8E,GAAGkD,WAAH,CAAe;uBAAMlD,GAAGiD,UAAH,CAAc/H,EAAEoE,EAAF,CAAd,CAAN;aAAf,CAAP;;;;oCAiBoBY,KAhzBxB;mBAizBWF,GAAGU,WAAH,CAAqB,UAACC,GAAD,EAAM9E,EAAN;oBACpBiF,OAAOH,IAAII,UAAjB;oBACMoC,OAAOxC,IAAIC,SAAJ,CAAcwC,YAAd,CAA2BlD,KAA3B,EAAkC;yBACxC1B,GAAL;uBACG6E,eAAIN,IAAJ,EAAH;iBAFW,CAAb;qBAIKlE,IAAL,CAAUsE,IAAV;aANK,CAAP;;;;yCAiCyB7I,IAl1B7B;mBAm1BWgJ,sBAAsBhJ,IAAtB,EAA4BiJ,kBAAOhB,gBAAnC,CAAP;;;;mCAamBzE,EAh2BvB;gBAi2BQ,CAACA,GAAG9C,KAAH,GAAWwI,OAAX,EAAL,EACE,OAAOxD,GAAGyD,OAAH,CAAc3F,GAAG9C,KAAH,GAAWY,GAAX,EAAd,CAAP;mBAEKoE,GAAGU,WAAH,CAAkB,UAACC,GAAD,EAAM9E,EAAN;oBACnBkF,UAAJ,CAAelC,IAAf,CAAoBf,EAApB;mBACG4F,UAAH,CAAc;wBACR3C,UAAJ,CAAevC,GAAf;uBACGmF,MAAH;iBAFF;aAFK,CAAP;;;;gCAagBvI,CAj3BpB;mBAi3B+C,IAAIwI,MAAJ,CAAWxI,CAAX,CAAP;;;;6BA2BvB0C,EA54BjB,EA44B4BwB,EA54B5B;mBA64BWU,GAAGC,KAAH,CAASX,EAAT,EAAa/D,OAAb,CAAqB;uBAAMuC,EAAN;aAArB,CAAP;;;;6BA6BAnB,GA16BJ,EA06BiBC,GA16BjB,EA26BI1B,CA36BJ;gBA66BU2B,KAAgBmD,GAAGlD,QAAH,CAAY,CAACH,GAAD,EAAMC,GAAN,CAAZ,CAAtB;mBACOC,GAAGpB,GAAH,CAAO;uBAAOP,EAAE6B,IAAI,CAAJ,CAAF,EAAUA,IAAI,CAAJ,CAAV,CAAP;aAAP,CAAP;;;;6BA6BAJ,GA38BJ,EA28BiBC,GA38BjB,EA28B8BI,GA38B9B,EA48BI9B,CA58BJ;gBA88BU2B,KAAgBmD,GAAGlD,QAAH,CAAY,CAACH,GAAD,EAAMC,GAAN,EAAWI,GAAX,CAAZ,CAAtB;mBACOH,GAAGpB,GAAH,CAAO;uBAAOP,EAAE6B,IAAI,CAAJ,CAAF,EAAUA,IAAI,CAAJ,CAAV,EAAkBA,IAAI,CAAJ,CAAlB,CAAP;aAAP,CAAP;;;;6BA6BAJ,GA5+BJ,EA4+BiBC,GA5+BjB,EA4+B8BI,GA5+B9B,EA4+B2CC,GA5+B3C,EA6+BI/B,CA7+BJ;gBA++BU2B,KAAgBmD,GAAGlD,QAAH,CAAY,CAACH,GAAD,EAAMC,GAAN,EAAWI,GAAX,EAAgBC,GAAhB,CAAZ,CAAtB;mBACOJ,GAAGpB,GAAH,CAAO;uBAAOP,EAAE6B,IAAI,CAAJ,CAAF,EAAUA,IAAI,CAAJ,CAAV,EAAkBA,IAAI,CAAJ,CAAlB,EAA0BA,IAAI,CAAJ,CAA1B,CAAP;aAAP,CAAP;;;;6BAgCAJ,GAhhCJ,EAghCiBC,GAhhCjB,EAghC8BI,GAhhC9B,EAghC2CC,GAhhC3C,EAghCwDC,GAhhCxD,EAihCIhC,CAjhCJ;gBAmhCU2B,KAAgBmD,GAAGlD,QAAH,CAAY,CAACH,GAAD,EAAMC,GAAN,EAAWI,GAAX,EAAgBC,GAAhB,EAAqBC,GAArB,CAAZ,CAAtB;mBACOL,GAAGpB,GAAH,CAAO;uBAAOP,EAAE6B,IAAI,CAAJ,CAAF,EAAUA,IAAI,CAAJ,CAAV,EAAkBA,IAAI,CAAJ,CAAlB,EAA0BA,IAAI,CAAJ,CAA1B,EAAkCA,IAAI,CAAJ,CAAlC,CAAP;aAAP,CAAP;;;;6BAkCAJ,GAtjCJ,EAsjCiBC,GAtjCjB,EAsjC8BI,GAtjC9B,EAsjC2CC,GAtjC3C,EAsjCwDC,GAtjCxD,EAsjCqEC,GAtjCrE,EAujCIjC,CAvjCJ;gBAyjCU2B,KAAgBmD,GAAGlD,QAAH,CAAY,CAACH,GAAD,EAAMC,GAAN,EAAWI,GAAX,EAAgBC,GAAhB,EAAqBC,GAArB,EAA0BC,GAA1B,CAAZ,CAAtB;mBACON,GAAGpB,GAAH,CAAO;uBAAOP,EAAE6B,IAAI,CAAJ,CAAF,EAAUA,IAAI,CAAJ,CAAV,EAAkBA,IAAI,CAAJ,CAAlB,EAA0BA,IAAI,CAAJ,CAA1B,EAAkCA,IAAI,CAAJ,CAAlC,EAA0CA,IAAI,CAAJ,CAA1C,CAAP;aAAP,CAAP;;;;4BAOY/B,KAjkChB;mBAikC0C,IAAI4I,MAAJ,CAAWC,mBAAQ7I,KAAR,CAAX,CAAP;;;;2BAKpBe,KAtkCf;mBAukCWiE,GAAGhE,MAAH,CAAUD,KAAV,CAAP;;;;6BAcaA,KArlCjB;mBAslCW,IAAI6F,MAAJ,CAAW7F,KAAX,EAAkB,KAAlB,CAAP;;;;gCA6BAY,GAnnCJ,EAmnCiBC,GAnnCjB,EAonCI1B,CApnCJ;gBAsnCU2B,KAAgBmD,GAAG8D,MAAH,CAAU,CAACnH,GAAD,EAAMC,GAAN,CAAV,CAAtB;mBACOC,GAAGpB,GAAH,CAAO;uBAAOP,EAAE6B,IAAI,CAAJ,CAAF,EAAUA,IAAI,CAAJ,CAAV,CAAP;aAAP,CAAP;;;;gCA+BAJ,GAtpCJ,EAspCiBC,GAtpCjB,EAspC8BI,GAtpC9B,EAupCI9B,CAvpCJ;gBAypCU2B,KAAgBmD,GAAG8D,MAAH,CAAU,CAACnH,GAAD,EAAMC,GAAN,EAAWI,GAAX,CAAV,CAAtB;mBACOH,GAAGpB,GAAH,CAAO;uBAAOP,EAAE6B,IAAI,CAAJ,CAAF,EAAUA,IAAI,CAAJ,CAAV,EAAkBA,IAAI,CAAJ,CAAlB,CAAP;aAAP,CAAP;;;;gCA+BAJ,GAzrCJ,EAyrCiBC,GAzrCjB,EAyrC8BI,GAzrC9B,EAyrC2CC,GAzrC3C,EA0rCI/B,CA1rCJ;gBA4rCU2B,KAAgBmD,GAAG8D,MAAH,CAAU,CAACnH,GAAD,EAAMC,GAAN,EAAWI,GAAX,EAAgBC,GAAhB,CAAV,CAAtB;mBACOJ,GAAGpB,GAAH,CAAO;uBAAOP,EAAE6B,IAAI,CAAJ,CAAF,EAAUA,IAAI,CAAJ,CAAV,EAAkBA,IAAI,CAAJ,CAAlB,EAA0BA,IAAI,CAAJ,CAA1B,CAAP;aAAP,CAAP;;;;gCAkCAJ,GA/tCJ,EA+tCiBC,GA/tCjB,EA+tC8BI,GA/tC9B,EA+tC2CC,GA/tC3C,EA+tCwDC,GA/tCxD,EAguCIhC,CAhuCJ;gBAkuCU2B,KAAgBmD,GAAG8D,MAAH,CAAU,CAACnH,GAAD,EAAMC,GAAN,EAAWI,GAAX,EAAgBC,GAAhB,EAAqBC,GAArB,CAAV,CAAtB;mBACOL,GAAGpB,GAAH,CAAO;uBAAOP,EAAE6B,IAAI,CAAJ,CAAF,EAAUA,IAAI,CAAJ,CAAV,EAAkBA,IAAI,CAAJ,CAAlB,EAA0BA,IAAI,CAAJ,CAA1B,EAAkCA,IAAI,CAAJ,CAAlC,CAAP;aAAP,CAAP;;;;gCAoCAJ,GAvwCJ,EAuwCiBC,GAvwCjB,EAuwC8BI,GAvwC9B,EAuwC2CC,GAvwC3C,EAuwCwDC,GAvwCxD,EAuwCqEC,GAvwCrE,EAwwCIjC,CAxwCJ;gBA0wCU2B,KAAgBmD,GAAG8D,MAAH,CAAU,CAACnH,GAAD,EAAMC,GAAN,EAAWI,GAAX,EAAgBC,GAAhB,EAAqBC,GAArB,EAA0BC,GAA1B,CAAV,CAAtB;mBACON,GAAGpB,GAAH,CAAO;uBAAOP,EAAE6B,IAAI,CAAJ,CAAF,EAAUA,IAAI,CAAJ,CAAV,EAAkBA,IAAI,CAAJ,CAAlB,EAA0BA,IAAI,CAAJ,CAA1B,EAAkCA,IAAI,CAAJ,CAAlC,EAA0CA,IAAI,CAAJ,CAA1C,CAAP;aAAP,CAAP;;;;6BAQa/B,KAnxCjB;mBAmxC2CgF,GAAG1E,GAAH,CAAON,KAAP,CAAP;;;;8BAMV0C,CAzxC1B;mBAyxCwD,IAAIkG,MAAJ,CAAWf,mBAAQnF,CAAR,CAAX,CAAP;;;;iCAwB5BpD,IAjzCrB;mBAkzCWyJ,WAAWzJ,IAAX,CAAP;;;;+BA8BeA,IAh1CnB;mBAi1CWgJ,sBAAsBhJ,IAAtB,EAA4BiJ,kBAAOzG,QAAnC,CAAP;;;;8BAgDWwC,EAj4Cf;gBAk4CQ,CAACA,EAAL,EAAS,OAAO0E,iBAAP;mBACFC,QAAQ3E,EAAR,CAAP;;;;gCAOgBvD,KA14CpB;mBA24CWiE,GAAG+C,IAAH,GAAUxH,OAAV,CAAkB;uBAAMQ,OAAN;aAAlB,CAAP;;;;iCAWoBX,CAt5CxB,EAs5C8BF,CAt5C9B;gBAu5CQ;uBACKA,EAAEE,CAAF,EAAKG,OAAL,CAAa;wBACde,OAAOC,OAAP,EAAJ,EAAsB;+BACbyD,GAAG1E,GAAH,CAAOgB,OAAOV,GAAP,EAAP,CAAP;qBADF,MAEO;+BAEEoE,GAAGxD,QAAH,CAAYF,OAAOG,IAAP,GAAcb,GAAd,EAAZ,EAAiCV,CAAjC,CAAP;;iBALG,CAAP;aADF,CASE,OAAOwC,CAAP,EAAU;uBACHsC,GAAGK,KAAH,CAAS3C,CAAT,CAAP;;;;;;mBASKwG,SAAP;;;;oCAYoBvG,MAt7CxB,EAs7CuCwG,OAt7CvC,EAs7C2DtI,EAt7C3D;mBAu7CW8D,iBAAiBhC,MAAjB,EAAyBwG,QAAQvD,SAAjC,EAA4CuD,OAA5C,EAAqDtI,EAArD,EAAyD,IAAzD,EAA+D,IAA/D,EAAqE,IAArE,CAAP;;;;;;;;;oBAkBiBb,KAAnB;;;;;oBAAmB,GAAAA,KAAA;mBANV,GAAe,MAAf;;;;;EADagF;;AAexB,IAAMkE,YAA0B,IAAIN,MAAJ,CAAWP,eAAIN,IAAJ,EAAX,CAAhC;;;;;oBAkBchH,KAAZ,EAA4BqI,aAA5B;;;;;mBANS,GAAe,MAAf;eAQF7G,MAAL,GAAcxB,KAAd;eACKqI,aAAL,GAAqBA,aAArB;;;;;;;gBAII,KAAKA,aAAL,IAAsB,KAAK7G,MAA/B,EACE,OAAO,IAAIqE,MAAJ,CAAW,KAAKrE,MAAhB,EAAwB,KAAxB,CAAP,CADF,KAGE,OAAO,IAAP;;;;;gBAIE,KAAKA,MAAT,EAAiB;oBACToG,SAASN,eAAItE,EAAJ,CAAO,KAAKxB,MAAZ,CAAf;oBACIoG,OAAOU,SAAP,MAAsB,CAAC,KAAKD,aAAhC,EAA+C;2BAEtC,KAAK7G,MAAZ;2BACO,KAAK6G,aAAZ;yBACKE,KAAL,GAAaX,MAAb;;uBAEKA,MAAP;;mBAEK,KAAKW,KAAZ;;;;EA/BoBtE;;;;;sBA4CHjE,KAAnB;;;;;oBAAmB,GAAAA,KAAA;mBAFV,GAAiB,QAAjB;;;;;EADeiE;;;;;uBAkBNrC,MADlB,EAEkBzC,CAFlB,EAGkBqJ,CAHlB;;;;;qBACkB,GAAA5G,MAAA;gBACA,GAAAzC,CAAA;gBACA,GAAAqJ,CAAA;mBALT,GAAkB,SAAlB;;;;;EADmBvE;;;;;qBA8BA2C,QAA5B;;;;;wBAA4B,GAAAA,QAAA;oBAFnB,GAAgB,OAAhB;;;;;EADc3C;;;;;uBAaXrC,MAAZ,EAA2BmE,WAA3B;;;;;oBANS,GAAkB,SAAlB;gBAQFnE,MAAL,GAAcA,MAAd;gBACKgG,MAAL,GAAc,IAAd;gBACK7B,WAAL,GAAmBA,WAAnB;;;;;EAXuB9B;;AAwB3B,aAAA;uBAqBIY,SADF;YAEEG,iFAAgC,IAAIyD,4BAAJ;YAChChD,8EAAqB,EAAEiD,wBAAwB,KAA1B;;;aAEhB7D,SAAL,GAAiBA,SAAjB;aACKY,OAAL,GAAeA,OAAf;aACKT,UAAL,GAAkBA,UAAlB;;YAGIS,QAAQiD,sBAAZ,EACE,KAAKC,YAAL,GAAoB;mBAAM3D,WAAW4D,UAAX,EAAN;SAApB;;;;;;iBAaG/D,SAAL,CAAegE,UAAf,GAA4B,CAA5B;;;;;mBAQ+B,KAAP;;;;;;AAwB5B,IAAaC,WAAoB;SAE1B,aAAO3J,CAAP,EAAuB4C,EAAvB;eACHA,GAAGrC,GAAH,CAAOP,CAAP,CADG;KAF0B;;QAK3B,YAAOM,EAAP,EAA4BsC,EAA5B;eACFA,GAAGC,EAAH,CAAMvC,EAAN,CADE;KAL2B;;QAQ3BwE,GAAGhC,IARwB;;WAUxB,eAAO9C,CAAP,EAA2B4C,EAA3B;eACLA,GAAGvC,OAAH,CAAWL,CAAX,CADK;KAVwB;;cAarB,kBAAOA,CAAP,EAAoEE,CAApE;eACR4E,GAAGxD,QAAH,CAAYpB,CAAZ,EAAe;mBAAKF,EAAE+C,kBAAOC,IAAT,EAAsBD,kBAAOE,KAA7B,EAA2C/C,CAA3C,CAAL;SAAf,CADQ;;CAbL;;AAkBPgD,yBAAcC,mBAAd,CAAkC2B,EAAlC,EAAsC6E,QAAtC;;AAGA,gBAAA,CAAiBvF,EAAjB;WACSU,GAAGU,WAAH,CAAqB,UAACC,GAAD,EAAM9E,EAAN;SACzByD,MAAMqB,IAAIC,SAAX,EAAsBkE,YAAtB,CAAmC;mBAAMjJ,GAAGwH,eAAIN,IAAJ,EAAH,CAAN;SAAnC;KADK,CAAP;;;AAMF,IAAMiB,oBAA8BC,SAApC;;AAYA,uBAAA,CAAwB3F,MAAxB,EAA8CC,KAA9C;QACMrD,IAA4CoC,SAAhD;QACIgB,MAAJ,EAAYpD,IAAIoD,MAAJ,CAAZ,KACK,IAAIC,SAASA,MAAMzD,MAAN,GAAe,CAA5B,EAA+BI,IAAIqD,MAAMC,GAAN,EAAJ;QAChCtD,CAAJ,EAAO,OAAO,OAAOA,CAAP,KAAa,UAAb,GAA0BA,CAA1B,GAA8BA,EAAE,CAAF,CAArC;WACA,IAAP;;;AAIF,4BAAA,CAA6BoD,MAA7B,EAAmDC,KAAnD;QACMxD,SAAcuD,MAAlB;OACG;YACGvD,UAAU,OAAOA,MAAP,KAAkB,UAAhC,EAA4C,OAAOA,OAAO,CAAP,CAAP;iBACnCwD,QAAQA,MAAMC,GAAN,EAAR,GAAsB,IAA/B;KAFF,QAGSzD,MAHT;WAKO,IAAP;;;;6BAmBUoJ,OADV,EAEU1D,QAFV;;;oBACU,GAAA0D,OAAA;qBACA,GAAA1D,QAAA;oBARF,GAAU,KAAV;mBACA,GAAuB,IAAvB;kBACA,GAA0B,IAA1B;aAQDsE,UAAL,GAAkB,KAAKC,MAAL,CAAYrG,IAAZ,CAAiB,IAAjB,CAAlB;;;;;gCAGML,QAAsBC;iBACvBD,MAAL,GAAcA,MAAd;iBACKC,KAAL,GAAaA,KAAb;iBACK0G,OAAL,GAAe,IAAf;;;;+BAGKtB;gBACD,KAAKsB,OAAT,EAAkB;qBACXA,OAAL,GAAe,KAAf;iCAEE,IAAIrB,MAAJ,CAAWD,MAAX,CADF,EAEE,KAAKQ,OAAL,CAAavD,SAFf,EAGE,KAAKuD,OAHP,EAIE,KAAK1D,QAJP,EAKE,IALF,EAME,KAAKnC,MANP,EAOE,KAAKC,KAPP;aAFF,MAWO,IAAIoF,OAAOuB,SAAP,EAAJ,EAAwB;qBACxBf,OAAL,CAAavD,SAAb,CAAuBuE,aAAvB,CAAqCxB,OAAOyB,MAAP,GAAgBxJ,GAAhB,EAArC;;;;;;;AAMN,uBAAA,CACE+G,QADF,EAEEwB,OAFF,EAGEtI,EAHF,EAIEwJ,GAJF,EAKE/G,MALF,EAMEC,KANF,EAOE+G,UAPF;QASM,CAACnB,QAAQO,YAAR,EAAL,EAA6B;gBACnB9D,SAAR,CAAkBgE,UAAlB,GAA+BU,UAA/B;YAEMC,UAAUF,OAAO,IAAIG,eAAJ,CAAoBrB,OAApB,EAA6BtI,EAA7B,CAAvB;gBACQ4J,OAAR,CAAgBnH,MAAhB,EAAwBC,KAAxB;iBACS4F,OAAT,EAAkBoB,QAAQR,UAA1B;;;;AAKJ,uBAAA,CACEtG,KADF,EAEE0F,OAFF,EAGEtI,EAHF,EAIEwJ,GAJF,EAKEK,UALF,EAMEC,SANF;QAQM,CAACxB,QAAQO,YAAR,EAAL,EACEP,QAAQvD,SAAR,CAAkBkE,YAAlB,CAA+B;yBACZrG,KAAjB,EAAwB0F,QAAQvD,SAAhC,EAA2CuD,OAA3C,EAAoDtI,EAApD,EAAwDwJ,GAAxD,EAA6DK,UAA7D,EAAyEC,SAAzE;KADF;;;AAMJ,yBAAA,CACElH,KADF,EAEEmC,SAFF,EAGEuD,OAHF,EAIEtI,EAJF,EAKEwJ,GALF,EAMEK,UANF,EAOEC,SAPF;QASMjH,UAA8BD,KAAlC;QACIH,SAAuBoH,UAA3B;QACInH,QAA0BoH,SAA9B;QAEMC,UAAUhF,UAAUiF,cAAV,CAAyBC,oBAAzB,GAAgD,CAAhE;QACIR,aAAa1E,UAAUgE,UAA3B;WAEO,IAAP,EAAa;YACPlG,mBAAmB2E,cAAvB,EAA4B;gBACtB3E,QAAQ2F,SAAR,EAAJ,EAAyB;oBACjB1F,OAAOoH,eAAezH,MAAf,EAAuBC,KAAvB,CAAb;oBACI,CAACI,IAAL,EAAW;8BACCiG,UAAV,GAAuBU,UAAvB;2BACOzJ,GAAG6C,OAAH,CAAP;;oBAGE;8BACQC,KAAKD,QAAQ9C,GAAR,EAAL,CAAV;iBADF,CAEE,OAAO8B,CAAP,EAAU;8BACA2F,eAAIb,OAAJ,CAAY9E,CAAZ,CAAV;;aAVJ,MAYO;oBACCiB,QAAOqH,oBAAoB1H,MAApB,EAA4BC,KAA5B,CAAb;oBACI,CAACI,KAAL,EAAW;8BACCiG,UAAV,GAAuBU,UAAvB;2BACOzJ,GAAG6C,OAAH,CAAP;;oBAGE;8BACQC,MAAMD,QAAuB0G,MAAvB,GAAgCxJ,GAAhC,EAAN,CAAV;iBADF,CAEE,OAAO8B,CAAP,EAAU;8BACA2F,eAAIb,OAAJ,CAAY9E,CAAZ,CAAV;;;qBAIK,IAAT;gBACMuI,YAAaX,aAAa,CAAd,GAAmBM,OAArC;;gBAEIK,SAAJ,EAAe;6BACAA,SAAb;aADF,MAEO;oBACCtF,MAAMwD,WAAW,IAAI5C,SAAJ,CAAcX,SAAd,CAAvB;;oBAEMsF,QAAQxH,mBAAmB2E,cAAnB,GAAyB,IAAIO,MAAJ,CAAWlF,OAAX,CAAzB,GAA+CA,OAA7D;+BACewH,KAAf,EAAsBvF,GAAtB,EAA2B9E,EAA3B,EAA+BwJ,GAA/B,EAAoC/G,MAApC,EAA4CC,KAA5C;uBACOoC,IAAII,UAAX;;SArCJ,MAwCK,QAAQrC,QAAQhD,IAAhB;iBACE,MAAL;0BACagD,QAAwB1D,KAAnC;;iBAGG,QAAL;0BACYqI,eAAItE,EAAJ,CAAQL,QAA0B3C,KAAlC,CAAV;;iBAGG,MAAL;0BACa2C,QAAwByH,MAAxB,EAAX;;iBAGG,SAAL;oBACQC,QAA6B1H,OAAnC;oBACIJ,MAAJ,EAAY;wBACN,CAACC,KAAL,EAAYA,QAAQ,EAAR;0BACNM,IAAN,CAAWP,MAAX;;yBAGO,CAAC8H,MAAM7B,CAAP,GAAW6B,MAAMlL,CAAjB,GAAqB,CAACkL,MAAMlL,CAAP,EAAUkL,MAAM7B,CAAhB,CAA9B;0BACU6B,MAAMzI,MAAhB;;iBAGG,OAAL;oBACQ0I,QAAsB3H,OAA5B;oBACMiC,OAAMwD,WAAW,IAAI5C,SAAJ,CAAcX,SAAd,CAAvB;+BACeyF,MAAM1D,QAArB,EAA+BhC,IAA/B,EAAoC9E,EAApC,EAAwCwJ,GAAxC,EAA6C/G,MAA7C,EAAqDC,KAArD,EAA4D+G,UAA5D;uBACO3E,KAAII,UAAX;iBAEG,SAAL;oBACQc,MAAsBnD,OAA5B;uBACO4H,eAAezE,GAAf,EAAoBjB,SAApB,EAA+BuD,OAA/B,EAAwCtI,EAAxC,EAA4CyC,MAA5C,EAAoDC,KAApD,EAA2D+G,UAA3D,CAAP;;;;;AAMR,0BAAA,CACE7G,KADF,EAEEmC,SAFF,EAGEtC,MAHF,EAIEC,KAJF,EAKEgI,WALF;WAOShD,kBAAOiD,MAAP,CAAmB;YAClB7F,MAAM,IAAIY,SAAJ,CAAcX,SAAd,CAAZ;YACI2F,WAAJ,EACEE,eAAehI,KAAf,EAA6BkC,GAA7B,EAAkC9E,EAAlC,EAA6C,IAA7C,EAAmDyC,MAAnD,EAA2DC,KAA3D,EADF,KAGEoB,iBAAiBlB,KAAjB,EAA+BmC,SAA/B,EAA0CD,GAA1C,EAA+C9E,EAA/C,EAA0D,IAA1D,EAAgEyC,MAAhE,EAAwEC,KAAxE;eAEKoC,IAAII,UAAX;KAPK,CAAP;;;AAYF,4BAAA,CACEtC,KADF,EAEEmC,SAFF;QAIMlC,UAA8BD,KAAlC;QACIH,SAAuB,IAA3B;QACIC,QAA0B,IAA9B;QAEMqH,UAAUhF,UAAUiF,cAAV,CAAyBC,oBAAzB,GAAgD,CAAhE;QACIR,aAAa1E,UAAUgE,UAA3B;WAEO,IAAP,EAAa;YACPlG,mBAAmB2E,cAAvB,EAA4B;gBACtB3E,QAAQ2F,SAAR,EAAJ,EAAyB;oBACjB1F,OAAOoH,eAAezH,MAAf,EAAuBC,KAAvB,CAAb;oBACI,CAACI,IAAL,EAAW;8BACCiG,UAAV,GAAuBU,UAAvB;2BACO/B,kBAAOvF,IAAP,CAAYU,QAAQ9C,GAAR,EAAZ,CAAP;;oBAGE;8BACQ+C,KAAKD,QAAQ9C,GAAR,EAAL,CAAV;iBADF,CAEE,OAAO8B,CAAP,EAAU;8BACA,IAAIkG,MAAJ,CAAWP,eAAIb,OAAJ,CAAY9E,CAAZ,CAAX,CAAV;;aAVJ,MAYO;oBACC4C,MAAO5B,QAAuB0G,MAAvB,GAAgCxJ,GAAhC,EAAb;oBACM+C,SAAOqH,oBAAoB1H,MAApB,EAA4BC,KAA5B,CAAb;oBACI,CAACI,MAAL,EAAW;8BACCiG,UAAV,GAAuBU,UAAvB;2BACO/B,kBAAOlD,KAAP,CAAaC,GAAb,CAAP;;oBAGE;8BACQ3B,OAAK2B,GAAL,CAAV;iBADF,CAEE,OAAO5C,CAAP,EAAU;8BACA,IAAIkG,MAAJ,CAAWP,eAAIb,OAAJ,CAAY9E,CAAZ,CAAX,CAAV;;;qBAIK,IAAT;gBACMuI,YAAaX,aAAa,CAAd,GAAmBM,OAArC;;gBAEIK,SAAJ,EAAe;6BACAA,SAAb;aADF,MAEO;uBACES,kBAAkBhI,OAAlB,EAA2BkC,SAA3B,EAAsCtC,MAAtC,EAA8CC,KAA9C,EAAqD,IAArD,CAAP;;SAlCJ,MAqCK,QAAQG,QAAQhD,IAAhB;iBACE,MAAL;0BACagD,QAAwB1D,KAAnC;;iBAGG,QAAL;0BACYqI,eAAItE,EAAJ,CAAQL,QAA0B3C,KAAlC,CAAV;;iBAGG,MAAL;0BACa2C,QAAwByH,MAAxB,EAAX;;iBAGG,SAAL;oBACQC,QAA6B1H,OAAnC;oBACIJ,MAAJ,EAAY;wBACN,CAACC,KAAL,EAAYA,QAAQ,EAAR;0BACNM,IAAN,CAAWP,MAAX;;yBAGO,CAAC8H,MAAM7B,CAAP,GAAW6B,MAAMlL,CAAjB,GAAqB,CAACkL,MAAMlL,CAAP,EAAUkL,MAAM7B,CAAhB,CAA9B;0BACU6B,MAAMzI,MAAhB;;iBAGG,OAAL;iBACK,SAAL;uBACS+I,kBAAkBhI,OAAlB,EAA2BkC,SAA3B,EAAsCtC,MAAtC,EAA8CC,KAA9C,EAAqD,KAArD,CAAP;;;;;AAUR,uBAAA,CACEe,EADF,EAEEwB,IAFF,EAGEjF,EAHF;QAKM8K,SAAS,KAAb;WACO,UAACC,CAAD;YACD,CAACD,MAAL,EAAa;qBACF,IAAT;;eAIG9F,UAAH,CAAc;qBACPrC,GAAL;mBACGoI,CAAH;aAFF;SALF,MASO,IAAIA,EAAE1B,SAAF,EAAJ,EAAmB;eACrBC,aAAH,CAAiByB,EAAExB,MAAF,GAAWxJ,GAAX,EAAjB;;KAXJ;;;AAiBF,uBAAA,CACEkC,EADF,EAEEwB,EAFF,EAGE6E,OAHF,EAIEtI,EAJF,EAKE6J,UALF,EAMEC,SANF,EAOEL,UAPF;OAWKV,UAAH,GAAgBU,UAAhB;;QAEIuB,cAAJ;;QAII/I,GAAG6F,MAAP,EAAe;gBACL7F,GAAG6F,MAAX;KADF,MAEO;YAICzI,IAAIwL,kBAAkB5I,GAAGH,MAArB,EAAoC2B,EAApC,EAAwC,IAAxC,EAA8C,IAA9C,EAAoD,KAApD,CAAV;YAEIpE,EAAEF,KAAF,GAAUwI,OAAV,EAAJ,EAAyB;eACpBG,MAAH,GAAYzI,CAAZ;oBACQA,CAAR;cAEEwI,UAAF,CAAa;oBACPkD,EAAEvC,SAAF,MAAiB,CAACvG,GAAGgE,WAAzB,EAAsC;uBAEjC6B,MAAH,GAAYiD,CAAZ;;2BAEO9I,GAAGH,MAAV;iBAJF,MAKO;uBAGFgG,MAAH,GAAY,IAAZ;;aATJ;SAJF,MAgBO;oBACIzI,EAAEF,KAAF,GAAUY,GAAV,EAAT;;gBAEIiL,MAAMxC,SAAN,MAAqB,CAACvG,GAAGgE,WAA7B,EACEhE,GAAG6F,MAAH,GAAYkD,KAAZ;;;;QAMAxH,KAAYwH,iBAAiBxD,cAAjB,GACd,IAAIO,MAAJ,CAAWiD,KAAX,CADc,GAEd7G,GAAGiD,UAAH,CAAc4D,KAAd,CAFJ;qBAIiBxH,EAAjB,EAAqBC,EAArB,EAAyB6E,OAAzB,EAAkCtI,EAAlC,EAAsC,IAAtC,EAA4C6J,UAA5C,EAAwDC,SAAxD;;;AAOF,mBAAA,CAAuBrL,IAAvB;WACS0F,GAAGjB,EAAH,CAAM;eAAMC,WAAW1E,IAAX,CAAN;KAAN,EACJiB,OADI,CACI;eAAUuL,eAAe,EAAf,EAAmB/L,MAAnB,CAAV;KADJ,CAAP;;;AAUF,uBAAA,CAA2BmE,GAA3B,EAAqCnE,MAArC;;YAEUoE,OAAOpE,OAAOX,IAAP,EAAb;YACMgF,SAASD,KAAK9E,IAApB;YAEI8E,KAAKnE,KAAT,EAAgB;gBACRqE,KAAYF,KAAKnE,KAAvB;;mBACOqE,GAAG9D,OAAH,CAAW;wBACZsD,IAAJ,CAASzD,CAAT;wBACIgE,MAAJ,EAAY,OAAOY,GAAGhC,IAAH,CAAQkB,GAAR,CAAP;2BACL4H,eAAe5H,GAAf,EAAoBnE,MAApB,CAAP;iBAHK;;SAFT,MAOO;gBAEDqE,MAAJ,EAAY;uBAAOY,GAAGhC,IAAH,CAAQkB,GAAR;;;;;WAbhB,IAAP,EAAa;;;;;;;AAmBf,8BAAA,CAAqC5E,IAArC,EAAsEY,CAAtE;WACS8E,GAAGU,WAAH,CAAkB,UAACC,GAAD,EAAM9E,EAAN;YACnB+E,SAAJ,CAAcC,UAAd,CAAyB;gBACnBkG,eAAe,IAAnB;gBACI;oBACIC,UAAuB,EAA7B;oBACMnM,QAAiBoM,yBAAcC,eAAd,CAA8B5M,IAA9B,CAAvB;+BACe,KAAf;qBAEK,IAAI6M,IAAI,CAAb,EAAgBA,IAAItM,MAAMC,MAA1B,EAAkCqM,GAAlC,EAAuC;wBAC/B9H,KAAKxE,MAAMsM,CAAN,CAAX;wBACMjM,KAAImE,GAAG2B,GAAH,CAAOL,IAAIC,SAAX,CAAV;4BACQ/B,IAAR,CAAa3D,EAAb;;oBAGIkM,MAAMlM,EAAE8L,OAAF,EAAWrG,IAAIC,SAAf,CAAZ;oBACIG,UAAJ,CAAelC,IAAf,CAAoBuI,GAApB;oBACI1D,UAAJ,CAAexC,eAAeP,IAAIC,SAAnB,EAA8BD,IAAII,UAAlC,EAA8ClF,EAA9C,CAAf;aAbF,CAcE,OAAO6B,CAAP,EAAU;oBAENqJ,YAAJ,EAAkBlL,GAAGgH,mBAAQnF,CAAR,CAAH,EAAlB,KACKiD,IAAIC,SAAJ,CAAcuE,aAAd,CAA4BzH,CAA5B;;SAnBT;KADK,CAAP;;;;;;;;;;;;;;;;;"}